FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.144666 -0.004769 0.113876 
scale_deviation_in=0.013598 0.017177 0.012095 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.603528 2.212364 -1.675085 
scale_deviation_out=0.119146 0.220659 0.308324 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.60213863849639892578e-01) (1, 5.36211967468261718750e-01) (2, -6.33406937122344970703e-01) (3, 2.13904287666082382202e-02) (0, -8.80161941051483154297e-01) (1, -1.02559745311737060547e+00) (2, 2.97719508409500122070e-01) (3, -6.17922246456146240234e-01) (0, -7.12170481681823730469e-01) (1, 6.52901232242584228516e-02) (2, -1.17427706718444824219e+00) (3, 5.45653522014617919922e-01) (0, 1.98323816061019897461e-01) (1, 6.76087677478790283203e-01) (2, 7.61398017406463623047e-01) (3, -6.96333229541778564453e-01) (0, -1.25968956947326660156e+00) (1, -3.43385264277458190918e-02) (2, -1.21253669261932373047e+00) (3, 2.80985563993453979492e-01) (0, -5.60545146465301513672e-01) (1, 1.52128800749778747559e-01) (2, -3.35822701454162597656e-02) (3, -3.64540815353393554688e-02) (0, -9.44739580154418945312e-01) (1, -8.41912269592285156250e-01) (2, -1.09188365936279296875e+00) (3, 1.63887947797775268555e-01) (0, -1.76242902874946594238e-01) (1, -3.67482155561447143555e-01) (2, -4.76518571376800537109e-01) (3, 4.41496133804321289062e-01) (0, 6.25108778476715087891e-01) (1, 8.44226956367492675781e-01) (2, -4.46527034044265747070e-01) (3, -1.01364505290985107422e+00) (0, 8.64511311054229736328e-01) (1, -1.45156896114349365234e+00) (2, -3.88211682438850402832e-02) (3, -4.86631870269775390625e-01) (4, 1.29474759101867675781e-01) (5, -8.98744165897369384766e-01) (6, 6.11198008060455322266e-01) (7, 1.06119561195373535156e+00) (8, 2.65445053577423095703e-01) (9, 4.70421403646469116211e-01) (10, -1.18484961986541748047e+00) (11, 4.04832780361175537109e-01) (12, 1.12101638317108154297e+00) (13, -1.37870001792907714844e+00) (14, 1.58615559339523315430e-01) (4, 2.29095235466957092285e-01) (5, 1.37405544519424438477e-01) (6, 4.88723963499069213867e-01) (7, 3.58508437871932983398e-01) (8, 1.11729788780212402344e+00) (9, 8.59328269958496093750e-01) (10, 1.65676558017730712891e+00) (11, -2.42493703961372375488e-01) (12, -6.29773437976837158203e-01) (13, -1.16244781017303466797e+00) (14, -4.84206199645996093750e-01) (4, 1.34311378002166748047e+00) (5, 7.42715060710906982422e-01) (6, 1.06638252735137939453e+00) (7, -1.01461267471313476562e+00) (8, 1.52041351795196533203e+00) (9, -5.74587844312191009521e-02) (10, 2.01940208673477172852e-01) (11, -4.05733078718185424805e-01) (12, 3.57719719409942626953e-01) (13, -2.78577774763107299805e-01) (14, -2.57210701704025268555e-01) 
