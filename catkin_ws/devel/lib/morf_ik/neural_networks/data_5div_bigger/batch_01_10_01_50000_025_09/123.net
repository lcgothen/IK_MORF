FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.046980 0.115038 0.025611 
scale_deviation_in=0.014798 0.017287 0.013296 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.389402 2.790302 -0.346055 
scale_deviation_out=0.123709 0.299253 0.234117 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.04382142424583435059e-01) (1, -3.98095071315765380859e-01) (2, 6.24447107315063476562e-01) (3, -2.12619468569755554199e-01) (0, -5.39465069770812988281e-01) (1, -8.43499302864074707031e-01) (2, 4.70239102840423583984e-01) (3, 5.57960152626037597656e-01) (0, 1.00466549396514892578e+00) (1, -9.69433605670928955078e-01) (2, 7.11139738559722900391e-01) (3, -7.62419462203979492188e-01) (0, -1.39248037338256835938e+00) (1, 1.97630137205123901367e-01) (2, 5.02901792526245117188e-01) (3, 1.52571752667427062988e-01) (0, -7.08079874515533447266e-01) (1, 2.85978555679321289062e-01) (2, 7.81119823455810546875e-01) (3, -2.29484543204307556152e-01) (0, 3.95659692585468292236e-02) (1, -1.60993194580078125000e+00) (2, -2.70418703556060791016e-01) (3, -4.83856260776519775391e-01) (0, 6.04927003383636474609e-01) (1, 1.25404804944992065430e-01) (2, 1.71477511525154113770e-01) (3, 5.70143699645996093750e-01) (0, -2.70746201276779174805e-01) (1, -8.07158946990966796875e-01) (2, -1.01824307441711425781e+00) (3, -3.90450581908226013184e-02) (0, 4.04489517211914062500e-01) (1, 1.27130413055419921875e+00) (2, 5.48503339290618896484e-01) (3, -3.97507697343826293945e-01) (0, -8.30758869647979736328e-01) (1, -3.79791706800460815430e-01) (2, -6.08374059200286865234e-01) (3, -7.31424331665039062500e-01) (4, 2.58883506059646606445e-01) (5, 8.09375047683715820312e-01) (6, -1.43373084068298339844e+00) (7, 1.55080068111419677734e+00) (8, 4.79469686746597290039e-01) (9, -9.41199660301208496094e-01) (10, -3.97528022527694702148e-01) (11, 9.35359239578247070312e-01) (12, 7.64471173286437988281e-01) (13, 4.76849943399429321289e-01) (14, -3.81259262561798095703e-01) (4, 5.44612109661102294922e-01) (5, 1.41223788261413574219e+00) (6, 5.04629790782928466797e-01) (7, 5.19253671169281005859e-01) (8, 3.50890010595321655273e-01) (9, 1.63888418674468994141e+00) (10, -5.17408609390258789062e-01) (11, 5.30069589614868164062e-01) (12, -1.26586675643920898438e-01) (13, 3.54565173387527465820e-01) (14, 2.80091136693954467773e-01) (4, -1.21631816029548645020e-01) (5, 1.88518255949020385742e-01) (6, 1.85563504695892333984e-01) (7, 5.06882704794406890869e-02) (8, 2.83482611179351806641e-01) (9, 1.20484828948974609375e+00) (10, 4.67539697885513305664e-01) (11, 7.23819792270660400391e-01) (12, -1.60127782821655273438e+00) (13, 9.42391872406005859375e-01) (14, 1.40955522656440734863e-01) 
