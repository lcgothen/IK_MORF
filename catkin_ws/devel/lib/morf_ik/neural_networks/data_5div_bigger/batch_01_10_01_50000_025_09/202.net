FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.097622 -0.005018 0.071732 
scale_deviation_in=0.014775 0.017367 0.013354 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.621838 3.145086 -0.511753 
scale_deviation_out=0.179975 0.232195 0.202186 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.70658808946609497070e-01) (1, -1.02470302581787109375e+00) (2, -4.79033857583999633789e-01) (3, 5.47223925590515136719e-01) (0, -9.13855254650115966797e-01) (1, 9.09926116466522216797e-01) (2, -4.78596597909927368164e-01) (3, 8.07246446609497070312e-01) (0, 8.22106823325157165527e-02) (1, 1.65199160575866699219e-01) (2, -1.37146878242492675781e+00) (3, -1.32469400763511657715e-01) (0, 2.76764392852783203125e-01) (1, 1.47530806064605712891e+00) (2, 4.05341923236846923828e-01) (3, 2.69529789686203002930e-01) (0, -6.56465649604797363281e-01) (1, -1.02476072311401367188e+00) (2, 3.61740469932556152344e-01) (3, -1.37575522065162658691e-01) (0, -1.17368447780609130859e+00) (1, -2.66506820917129516602e-01) (2, -1.34955406188964843750e-01) (3, 6.10333442687988281250e-01) (0, -8.42432975769042968750e-01) (1, 6.30109429359436035156e-01) (2, 1.17528212070465087891e+00) (3, -8.04758250713348388672e-01) (0, -1.27174568176269531250e+00) (1, 2.98627942800521850586e-01) (2, -9.03816819190979003906e-01) (3, -1.17055058479309082031e-01) (0, 7.08862021565437316895e-03) (1, 3.57621043920516967773e-01) (2, -6.26165688037872314453e-01) (3, -8.00697445869445800781e-01) (0, 5.43786287307739257812e-01) (1, 1.05341643095016479492e-01) (2, -5.93213856220245361328e-01) (3, -4.97360557317733764648e-01) (4, -9.70775544643402099609e-01) (5, 1.75016820430755615234e-01) (6, 3.25128525495529174805e-01) (7, 1.40961241722106933594e+00) (8, -1.31428205966949462891e+00) (9, 3.23133915662765502930e-01) (10, 7.13955342769622802734e-01) (11, 1.16307221353054046631e-01) (12, 4.52777892351150512695e-01) (13, 9.10505130887031555176e-02) (14, 3.05075734853744506836e-01) (4, 6.48519337177276611328e-01) (5, 1.03659331798553466797e+00) (6, 5.44176101684570312500e-01) (7, 5.17355352640151977539e-02) (8, 6.96791291236877441406e-01) (9, 8.38770687580108642578e-01) (10, 4.56818372011184692383e-01) (11, 1.33066582679748535156e+00) (12, 6.27352535724639892578e-01) (13, -9.29486334323883056641e-01) (14, -4.64740246534347534180e-01) (4, 1.13687403500080108643e-01) (5, 1.30584609508514404297e+00) (6, 8.62639784812927246094e-01) (7, -3.78433316946029663086e-01) (8, 6.16779267787933349609e-01) (9, -1.52893528342247009277e-01) (10, -9.32094573974609375000e-01) (11, 1.76502788066864013672e+00) (12, -1.50983966886997222900e-03) (13, -1.86805710196495056152e-01) (14, -5.04904448986053466797e-01) 
