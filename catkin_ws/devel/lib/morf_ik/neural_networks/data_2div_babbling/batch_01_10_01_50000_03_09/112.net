FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.170996 0.103384 0.033695 
scale_deviation_in=0.025269 0.032223 0.026062 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.025846 1.462458 -1.999611 
scale_deviation_out=0.180177 0.454301 0.667036 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.22367787361145019531e+00) (1, 1.39401495456695556641e+00) (2, 3.72451758384704589844e+00) (3, 3.01472091674804687500e+00) (0, 1.33721411228179931641e+00) (1, 5.46736538410186767578e-01) (2, -1.20410358905792236328e+00) (3, 5.32826375961303710938e+00) (0, -3.86968445777893066406e+00) (1, 1.12445573806762695312e+01) (2, -7.03270316123962402344e-01) (3, -1.21215820312500000000e+01) (0, 8.19080948829650878906e-01) (1, -1.16494429111480712891e+00) (2, 2.04602509737014770508e-01) (3, 1.72067439556121826172e+00) (0, 1.18040943145751953125e+00) (1, 7.50846326351165771484e-01) (2, -5.67245297133922576904e-02) (3, 2.66719907522201538086e-01) (0, 1.11467528343200683594e+00) (1, 6.46460711956024169922e-01) (2, 1.97658824920654296875e+00) (3, -1.60160756111145019531e+00) (0, -1.73581314086914062500e+00) (1, -3.34018588066101074219e-01) (2, -2.05038666725158691406e+00) (3, -2.97904539108276367188e+00) (0, -1.90631711483001708984e+00) (1, 1.16198310852050781250e+01) (2, -1.05292093753814697266e+00) (3, 1.24378490447998046875e+01) (0, -2.28882074356079101562e+00) (1, -8.84922206401824951172e-01) (2, -3.13939642906188964844e+00) (3, -4.62678575515747070312e+00) (0, -1.93576812744140625000e+00) (1, -9.10769999027252197266e-01) (2, -3.19247364997863769531e+00) (3, -3.28994417190551757812e+00) (4, -6.72384023666381835938e-01) (5, 1.29768931865692138672e+00) (6, 2.58309745788574218750e+01) (7, -5.07037830352783203125e+00) (8, -2.23665505647659301758e-01) (9, 1.81213334202766418457e-01) (10, -1.42273807525634765625e+00) (11, 2.57407798767089843750e+01) (12, 5.28388261795043945312e-01) (13, -6.86913609504699707031e-01) (14, 1.63549375534057617188e+00) (4, -5.31732225418090820312e+00) (5, -3.29685878753662109375e+00) (6, -3.54247868061065673828e-01) (7, 1.41701459884643554688e+00) (8, -7.08635234832763671875e+00) (9, -2.08699655532836914062e+00) (10, -3.49172496795654296875e+00) (11, 3.46380174160003662109e-01) (12, 4.39445400238037109375e+00) (13, -7.19259929656982421875e+00) (14, 1.96667051315307617188e+00) (4, -5.14567518234252929688e+00) (5, -1.75292718410491943359e+00) (6, -3.70212376117706298828e-01) (7, 1.38504087924957275391e+00) (8, -6.27712917327880859375e+00) (9, -3.04221057891845703125e+00) (10, -4.46466255187988281250e+00) (11, 3.53348612785339355469e-01) (12, 5.24139308929443359375e+00) (13, -5.44081115722656250000e+00) (14, 1.14682805538177490234e+00) 
