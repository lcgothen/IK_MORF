FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.078790 0.069038 0.157421 
scale_deviation_in=0.013420 0.015911 0.007681 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.853985 1.937045 -2.673837 
scale_deviation_out=0.100206 0.189799 0.300785 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.34240608215332031250e+01) (1, 3.13266162872314453125e+01) (2, 1.76832618713378906250e+01) (3, 9.65921096801757812500e+01) (0, -1.92609977722167968750e+01) (1, 8.20159378051757812500e+01) (2, 3.25439414978027343750e+01) (3, 4.36656494140625000000e+01) (0, 2.56644573211669921875e+01) (1, -8.13815155029296875000e+01) (2, -6.16798973083496093750e+00) (3, 2.25849933624267578125e+01) (0, -2.57187309265136718750e+01) (1, 4.32755584716796875000e+01) (2, -7.99112243652343750000e+01) (3, -2.90638961791992187500e+01) (0, -6.92461853027343750000e+01) (1, 7.20963439941406250000e+01) (2, -1.09684364318847656250e+02) (3, 5.15339660644531250000e+01) (0, 5.95616683959960937500e+01) (1, -4.75648651123046875000e+01) (2, 1.14862907409667968750e+02) (3, -5.94067192077636718750e+01) (0, 3.04968953132629394531e+00) (1, -2.53640937805175781250e+01) (2, 9.41455535888671875000e+01) (3, -7.58649978637695312500e+01) (0, -7.34322509765625000000e+01) (1, -3.35677642822265625000e+01) (2, -1.17786321640014648438e+01) (3, -9.60060195922851562500e+01) (0, -8.34235286712646484375e+00) (1, -1.86203022003173828125e+01) (2, -7.65726623535156250000e+01) (3, 6.29500007629394531250e+01) (0, 2.36076145172119140625e+01) (1, -5.45677185058593750000e+01) (2, -3.29540023803710937500e+01) (3, -5.26043891906738281250e+01) (4, -4.95003461837768554688e+00) (5, 2.12481746673583984375e+01) (6, -1.03957691192626953125e+01) (7, -2.29345649480819702148e-01) (8, 7.42689371109008789062e+00) (9, -1.92137336730957031250e+00) (10, 8.97443771362304687500e+00) (11, 5.88110733032226562500e+00) (12, -1.28801774978637695312e+01) (13, -1.51694822311401367188e+01) (14, -3.01893234252929687500e+00) (4, 6.12932395935058593750e+01) (5, 5.06040611267089843750e+01) (6, -2.45292530059814453125e+01) (7, -2.48465385437011718750e+01) (8, -4.26800003051757812500e+01) (9, 3.97453918457031250000e+01) (10, 3.66345520019531250000e+01) (11, -5.79676055908203125000e+01) (12, -4.08209266662597656250e+01) (13, -3.18766536712646484375e+01) (14, -4.23031616210937500000e+01) (4, 1.01747760772705078125e+01) (5, 2.77409523725509643555e-01) (6, -3.69123697280883789062e-01) (7, 1.51255294680595397949e-01) (8, -1.09644923359155654907e-02) (9, 3.62165957689285278320e-01) (10, 4.35250923037528991699e-02) (11, -6.95412540435791015625e+00) (12, -2.79662489891052246094e-01) (13, -8.13638791441917419434e-04) (14, -1.64597949981689453125e+01) 
