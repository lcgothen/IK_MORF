FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.127526 0.128035 0.042209 
scale_deviation_in=0.017792 0.020806 0.016357 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.785190 1.938338 -1.347396 
scale_deviation_out=0.112086 0.298513 0.386920 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.23684266209602355957e-01) (1, -3.70672672986984252930e-01) (2, 1.63902640342712402344e+00) (3, -1.67866361141204833984e+00) (0, 5.78366108238697052002e-02) (1, -2.30581879615783691406e-01) (2, 4.99419569969177246094e-01) (3, -2.23303943872451782227e-01) (0, 2.68873834609985351562e+00) (1, 3.39706039428710937500e+00) (2, 9.37316179275512695312e-01) (3, -4.87732124328613281250e+00) (0, -9.36810433864593505859e-01) (1, -1.67897745966911315918e-01) (2, -3.09277057647705078125e-01) (3, -9.72244024276733398438e-01) (0, 3.16072925925254821777e-02) (1, -9.59109246730804443359e-01) (2, -3.24157208204269409180e-01) (3, -5.94564855098724365234e-01) (0, -3.15610915422439575195e-01) (1, -1.02087724208831787109e+00) (2, 3.42411279678344726562e-01) (3, -1.28157937526702880859e+00) (0, -2.90985584259033203125e-01) (1, 8.96225810050964355469e-01) (2, -3.06510508060455322266e-01) (3, -6.56411290168762207031e-01) (0, -1.29227817058563232422e+00) (1, 1.99654102325439453125e-01) (2, 2.17852726578712463379e-01) (3, -1.42890238761901855469e+00) (0, 1.02684032917022705078e+00) (1, -6.59275829792022705078e-01) (2, -1.83553487062454223633e-01) (3, -1.42926394939422607422e+00) (0, 8.28824877738952636719e-01) (1, 8.19367945194244384766e-01) (2, 3.77838134765625000000e-01) (3, 1.81547605991363525391e+00) (4, 2.34422273933887481689e-02) (5, -1.17345072329044342041e-01) (6, -4.84638847410678863525e-02) (7, 1.30415236949920654297e+00) (8, -1.76858794689178466797e+00) (9, -1.66707932949066162109e+00) (10, 1.16319215297698974609e+00) (11, 2.36336779594421386719e+00) (12, -1.50391185283660888672e+00) (13, 2.38059222698211669922e-01) (14, -1.63462281227111816406e-01) (4, -8.59135270118713378906e-01) (5, 3.99914443492889404297e-01) (6, -2.80833888053894042969e+00) (7, 9.32284653186798095703e-01) (8, 9.84652936458587646484e-01) (9, 2.37514734268188476562e+00) (10, -2.56787467002868652344e+00) (11, 9.21931862831115722656e-01) (12, -2.35455679893493652344e+00) (13, -6.55048847198486328125e-01) (14, -1.97348213195800781250e+00) (4, -1.14615058898925781250e+00) (5, 8.83187949657440185547e-02) (6, -3.37191843986511230469e+00) (7, 1.59800660610198974609e+00) (8, 1.59668970108032226562e+00) (9, 1.09049892425537109375e+00) (10, -1.02171254158020019531e+00) (11, -5.34256160259246826172e-01) (12, -1.57806921005249023438e+00) (13, -2.42484045028686523438e+00) (14, -1.52936041355133056641e+00) 
