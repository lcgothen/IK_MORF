FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.065787 0.055525 0.100555 
scale_deviation_in=0.018503 0.021884 0.016705 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.879671 3.080112 -0.842060 
scale_deviation_out=0.237722 0.279200 0.280295 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.84000116586685180664e-01) (1, 4.30196434259414672852e-01) (2, 9.97844934463500976562e-01) (3, -2.79369860887527465820e-01) (0, 9.00527954101562500000e-01) (1, -5.86540877819061279297e-01) (2, 9.14014756679534912109e-01) (3, 4.57697026431560516357e-02) (0, -1.78495037555694580078e+00) (1, -1.86284887790679931641e+00) (2, -8.33477497100830078125e-01) (3, 4.74758028984069824219e-01) (0, 1.67255473136901855469e+00) (1, -2.59093046188354492188e-01) (2, -1.77398603409528732300e-03) (3, -1.13644313812255859375e+00) (0, 1.32074248790740966797e+00) (1, -3.26235127449035644531e+00) (2, -7.50161185860633850098e-02) (3, -4.05003595352172851562e+00) (0, -2.09660363197326660156e+00) (1, 1.82754480838775634766e+00) (2, -3.97337153553962707520e-02) (3, -3.36901664733886718750e+00) (0, -1.40925645828247070312e+00) (1, -4.86734777688980102539e-01) (2, 3.07843506336212158203e-01) (3, 7.97247141599655151367e-02) (0, -5.23857235908508300781e-01) (1, -1.36348497867584228516e+00) (2, 3.89400124549865722656e-01) (3, 2.33668401837348937988e-01) (0, 3.39391343295574188232e-02) (1, 4.17189478874206542969e-01) (2, -1.10392606258392333984e+00) (3, 4.66731697320938110352e-01) (0, -3.38333249092102050781e-01) (1, 1.85822308063507080078e+00) (2, -8.93146637827157974243e-03) (3, -1.29139780998229980469e+00) (4, 1.43382632732391357422e+00) (5, -1.16996981203556060791e-01) (6, -1.91339656710624694824e-01) (7, -3.22921238839626312256e-02) (8, -4.18738937377929687500e+00) (9, 3.84506416320800781250e+00) (10, 1.12582707405090332031e+00) (11, -1.07193613052368164062e+00) (12, 1.27525496482849121094e+00) (13, -1.28377348184585571289e-01) (14, -4.24274921417236328125e-01) (4, -2.59613466262817382812e+00) (5, -2.29534888267517089844e+00) (6, -1.87191772460937500000e+00) (7, -2.16192650794982910156e+00) (8, 6.67801260948181152344e-01) (9, 7.86374330520629882812e-01) (10, 2.27240705490112304688e+00) (11, 2.23705983161926269531e+00) (12, 1.72031283378601074219e+00) (13, -3.34166622161865234375e+00) (14, -1.65568733215332031250e+00) (4, -2.12850737571716308594e+00) (5, -7.82061219215393066406e-01) (6, 8.72600078582763671875e-01) (7, -1.60485184192657470703e+00) (8, 2.31726899743080139160e-01) (9, 5.11119484901428222656e-01) (10, -2.82807081937789916992e-01) (11, -1.36139541864395141602e-01) (12, 2.51452994346618652344e+00) (13, -1.69006454944610595703e+00) (14, -1.44670796394348144531e+00) 
