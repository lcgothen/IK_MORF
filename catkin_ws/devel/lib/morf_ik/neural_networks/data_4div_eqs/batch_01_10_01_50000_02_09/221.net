FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.065963 0.130228 0.042904 
scale_deviation_in=0.018422 0.021743 0.016611 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.471245 2.468999 -0.774508 
scale_deviation_out=0.132355 0.314382 0.321548 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.06974709033966064453e-01) (1, -5.18599092960357666016e-01) (2, -7.69940137863159179688e-01) (3, 8.12173008918762207031e-01) (0, 8.21837961673736572266e-01) (1, 1.55311301350593566895e-01) (2, 8.28211605548858642578e-02) (3, 4.47917103767395019531e-01) (0, -3.77246499061584472656e-01) (1, 5.40808558464050292969e-01) (2, -1.13947784900665283203e+00) (3, -1.07917535305023193359e+00) (0, -4.97572153806686401367e-01) (1, 3.10885399580001831055e-01) (2, -1.17431366443634033203e+00) (3, 4.41084414720535278320e-01) (0, 8.59124302864074707031e-01) (1, -1.85937166213989257812e+00) (2, -3.25922742486000061035e-02) (3, -2.77343797683715820312e+00) (0, 1.34987843036651611328e+00) (1, 9.49221998453140258789e-02) (2, 1.30575597286224365234e-01) (3, 1.79030179977416992188e+00) (0, -7.80549287796020507812e-01) (1, 1.33495354652404785156e+00) (2, -9.91496071219444274902e-03) (3, -7.52641022205352783203e-01) (0, 1.54986947774887084961e-01) (1, 1.37582361698150634766e+00) (2, -6.85279846191406250000e-01) (3, -9.25459206104278564453e-01) (0, -1.39845919609069824219e+00) (1, 2.29939129203557968140e-02) (2, -5.86372949182987213135e-02) (3, 1.02694165706634521484e+00) (0, 8.85771453380584716797e-01) (1, 2.70931214094161987305e-01) (2, -7.39342629909515380859e-01) (3, -3.05227428674697875977e-01) (4, -1.29543519020080566406e+00) (5, -9.53400969505310058594e-01) (6, -5.59743195772171020508e-02) (7, 7.41781175136566162109e-01) (8, -2.93897485733032226562e+00) (9, -2.45230746269226074219e+00) (10, 1.62501052021980285645e-01) (11, 1.18980073928833007812e+00) (12, 5.84730803966522216797e-01) (13, -1.04791963100433349609e+00) (14, -1.78964689373970031738e-01) (4, 1.59520244598388671875e+00) (5, -1.64277839660644531250e+00) (6, -1.39248323440551757812e+00) (7, 3.41424584388732910156e-01) (8, 1.11381566524505615234e+00) (9, -1.24160659313201904297e+00) (10, -2.99096751213073730469e+00) (11, -8.51847454905509948730e-02) (12, 2.01992678642272949219e+00) (13, -1.23706722259521484375e+00) (14, -1.01656568050384521484e+00) (4, 2.06578850746154785156e+00) (5, -7.32224345207214355469e-01) (6, 8.26690614223480224609e-01) (7, 1.58218753337860107422e+00) (8, 8.80500137805938720703e-01) (9, -6.02298021316528320312e-01) (10, -1.78038573265075683594e+00) (11, -2.36285328865051269531e+00) (12, 1.88136184215545654297e+00) (13, -3.54344211518764495850e-02) (14, -1.36444103717803955078e+00) 
