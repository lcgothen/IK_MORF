FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.002119 0.130435 -0.014564 
scale_deviation_in=0.018478 0.021604 0.016566 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.016201 2.410206 -0.302578 
scale_deviation_out=0.145335 0.376927 0.311494 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.15683662891387939453e+00) (1, 8.25113713741302490234e-01) (2, -8.44651818275451660156e-01) (3, 4.59903955459594726562e-01) (0, 4.35931563377380371094e-01) (1, -4.98270839452743530273e-01) (2, 9.03577566146850585938e-01) (3, 4.52801845967769622803e-02) (0, 2.55432248115539550781e-01) (1, 9.67897415161132812500e-01) (2, 1.00923252105712890625e+00) (3, 1.85058936476707458496e-01) (0, -2.09326371550559997559e-01) (1, -1.32809412479400634766e+00) (2, 1.16313494741916656494e-01) (3, 3.25257748365402221680e-01) (0, 4.11234855651855468750e-01) (1, -5.16252160072326660156e-01) (2, 3.88551980257034301758e-01) (3, 7.58054554462432861328e-01) (0, -6.29436969757080078125e-01) (1, 9.52015995979309082031e-01) (2, 2.67312824726104736328e-01) (3, -4.50083851814270019531e-01) (0, -5.02895832061767578125e-01) (1, 1.67516097426414489746e-01) (2, 4.38341975212097167969e-01) (3, -2.53490179777145385742e-01) (0, 1.52863550186157226562e+00) (1, 3.13982486724853515625e-01) (2, 5.95741510391235351562e-01) (3, 6.34735465049743652344e-01) (0, -9.84451115131378173828e-01) (1, -2.27898001670837402344e-01) (2, 4.55443412065505981445e-01) (3, 9.12554502487182617188e-01) (0, 4.17872279882431030273e-01) (1, -1.52648365497589111328e+00) (2, 3.35170447826385498047e-01) (3, -3.53579461574554443359e-01) (4, -1.71298432350158691406e+00) (5, -5.21585047245025634766e-01) (6, 1.60032242536544799805e-01) (7, 2.06122219562530517578e-01) (8, -4.77168053388595581055e-01) (9, 6.33733332157135009766e-01) (10, 1.76045045256614685059e-01) (11, -2.19563388824462890625e+00) (12, 9.41745758056640625000e-01) (13, -8.90124559402465820312e-01) (14, 6.54695391654968261719e-01) (4, -1.51851475238800048828e+00) (5, 1.27982568740844726562e+00) (6, 4.09964919090270996094e-01) (7, 6.13358676433563232422e-01) (8, -1.55903726816177368164e-01) (9, -7.81132459640502929688e-01) (10, -3.76565545797348022461e-01) (11, 2.17767879366874694824e-01) (12, 6.84180557727813720703e-01) (13, 1.78212642669677734375e+00) (14, -2.54207670688629150391e-01) (4, -2.33461648225784301758e-01) (5, 2.63537541031837463379e-02) (6, -1.48494946956634521484e+00) (7, 1.21319115161895751953e+00) (8, 3.66714239120483398438e-01) (9, -6.70293390750885009766e-01) (10, 2.30515271425247192383e-01) (11, 1.54990777373313903809e-01) (12, 7.45425701141357421875e-01) (13, 1.78356444835662841797e+00) (14, -2.98353135585784912109e-01) 
