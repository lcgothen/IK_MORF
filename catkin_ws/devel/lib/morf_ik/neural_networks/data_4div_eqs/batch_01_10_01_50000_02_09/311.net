FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.002204 0.057986 0.046394 
scale_deviation_in=0.018430 0.021729 0.015161 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.039110 4.047191 0.052607 
scale_deviation_out=0.366779 0.481989 0.229946 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.40559867024421691895e-02) (1, 4.74966001510620117188e+00) (2, 4.36966085433959960938e+00) (3, 7.02016067504882812500e+00) (0, 1.11119174957275390625e+00) (1, -5.99407613277435302734e-01) (2, 9.78371083736419677734e-01) (3, -4.18332606554031372070e-01) (0, -1.04669988155364990234e-01) (1, -5.64058363437652587891e-01) (2, 4.62021291255950927734e-01) (3, 1.93823826313018798828e+00) (0, -3.92435503005981445312e+00) (1, 2.35404086112976074219e+00) (2, 7.46495723724365234375e-02) (3, 5.56649494171142578125e+00) (0, 2.52228784561157226562e+00) (1, 9.88616704940795898438e-01) (2, 5.24582982063293457031e-01) (3, 4.36134290695190429688e+00) (0, -5.00726327300071716309e-02) (1, 1.61387038230895996094e+00) (2, 9.67854559421539306641e-02) (3, -8.99432837963104248047e-01) (0, -1.27427041530609130859e+00) (1, -2.26356935501098632812e+00) (2, -1.04937887191772460938e+00) (3, -3.36802482604980468750e+00) (0, -6.49697303771972656250e-01) (1, -4.38256174325942993164e-01) (2, 1.15032160282135009766e+00) (3, -2.12005555629730224609e-01) (0, 1.27178356051445007324e-01) (1, 1.92256450653076171875e+00) (2, 3.42802077531814575195e-01) (3, -2.78151869773864746094e+00) (0, 1.83003485202789306641e+00) (1, 9.49639439582824707031e-01) (2, -3.46833616495132446289e-01) (3, 3.35807704925537109375e+00) (4, 8.11330974102020263672e-01) (5, -9.92538928985595703125e-01) (6, 4.24222171306610107422e-01) (7, 7.44047260284423828125e+00) (8, -4.17228984832763671875e+00) (9, 1.08885633945465087891e+00) (10, 1.93678808212280273438e+00) (11, 8.58691334724426269531e-01) (12, -8.74402046203613281250e-01) (13, -3.48003149032592773438e+00) (14, 6.49406909942626953125e-02) (4, -1.08882484436035156250e+01) (5, -1.22421360015869140625e+00) (6, 3.66070771217346191406e+00) (7, 2.95584380626678466797e-01) (8, 2.39334321022033691406e+00) (9, -1.57623040676116943359e+00) (10, 2.49666595458984375000e+00) (11, -1.24334657192230224609e+00) (12, -4.32742929458618164062e+00) (13, 1.07538104057312011719e+00) (14, 2.48557424545288085938e+00) (4, -1.98052752017974853516e+00) (5, -2.14402246475219726562e+00) (6, -1.38207328319549560547e+00) (7, 1.73031732439994812012e-01) (8, -4.39544051885604858398e-01) (9, -2.88379788398742675781e+00) (10, -2.19336286187171936035e-01) (11, -2.82618308067321777344e+00) (12, -2.48430061340332031250e+00) (13, 8.49868774414062500000e-01) (14, -1.20173513889312744141e+00) 
