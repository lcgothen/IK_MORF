FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.151634 0.097365 0.008414 
scale_deviation_in=0.014540 0.013986 0.010358 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.999613 1.933257 -1.112384 
scale_deviation_out=0.083301 0.189047 0.246137 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.99811547994613647461e-01) (1, -7.52586901187896728516e-01) (2, -5.87393641471862792969e-01) (3, -2.37225174903869628906e-01) (0, -1.41141533851623535156e+00) (1, 3.23841303586959838867e-01) (2, 3.01574170589447021484e-01) (3, 1.07122159004211425781e+00) (0, 1.09703409671783447266e+00) (1, -2.95008659362792968750e-01) (2, -1.86739623546600341797e-01) (3, 1.57920885086059570312e+00) (0, 6.30217552185058593750e-01) (1, -1.85581818222999572754e-01) (2, -2.48325467109680175781e-01) (3, 2.35052183270454406738e-02) (0, -4.90049831569194793701e-02) (1, 1.11682653427124023438e+00) (2, -3.60412865877151489258e-01) (3, 1.17689013481140136719e+00) (0, -2.09642704576253890991e-02) (1, -8.49952042102813720703e-01) (2, 8.31636637449264526367e-02) (3, -9.51616287231445312500e-01) (0, 4.06433671712875366211e-01) (1, 1.60953640937805175781e+00) (2, -2.97434180974960327148e-01) (3, -1.87101221084594726562e+00) (0, -7.78062760829925537109e-01) (1, 4.07243698835372924805e-01) (2, -4.20446366071701049805e-01) (3, -1.14226698875427246094e+00) (0, 6.68168589472770690918e-02) (1, 7.06407666206359863281e-01) (2, 3.18307220935821533203e-01) (3, 2.37279057502746582031e-01) (0, -8.06226491928100585938e-01) (1, -1.14027097821235656738e-01) (2, -6.79086327552795410156e-01) (3, 9.89996969699859619141e-01) (4, -4.04219537973403930664e-01) (5, 5.32952606678009033203e-01) (6, -1.87035226821899414062e+00) (7, -5.04422962665557861328e-01) (8, 9.28980588912963867188e-01) (9, -2.35297513008117675781e+00) (10, 9.60054025053977966309e-02) (11, 1.30544805526733398438e+00) (12, 1.70320975780487060547e+00) (13, 6.94768846035003662109e-01) (14, -3.44847768545150756836e-01) (4, -2.39845260977745056152e-01) (5, 2.22222566604614257812e+00) (6, -1.64798223972320556641e+00) (7, -1.75003635883331298828e+00) (8, -2.05845499038696289062e+00) (9, 1.06307387351989746094e+00) (10, -2.54833722114562988281e+00) (11, -4.29028093814849853516e-01) (12, -9.88075584173202514648e-02) (13, 1.27703547477722167969e+00) (14, -8.37977647781372070312e-01) (4, 1.72940754890441894531e+00) (5, 2.39280438423156738281e+00) (6, -6.54508888721466064453e-01) (7, -1.32785212993621826172e+00) (8, -1.14338003098964691162e-01) (9, 1.20141732692718505859e+00) (10, -1.88801050186157226562e+00) (11, 1.57449233531951904297e+00) (12, -1.39005112648010253906e+00) (13, 6.84549391269683837891e-01) (14, -3.24699878692626953125e-01) 
