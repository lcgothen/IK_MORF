FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.098030 0.046445 0.156114 
scale_deviation_in=0.015233 0.014419 0.006789 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.127693 1.925585 -2.655091 
scale_deviation_out=0.134907 0.193669 0.305585 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.44001054763793945312e+00) (1, -9.53684896230697631836e-02) (2, 1.92861664295196533203e+00) (3, 8.25529918074607849121e-03) (0, -1.43075183033943176270e-01) (1, -1.21174323558807373047e+00) (2, -8.98616015911102294922e-01) (3, -1.90275764465332031250e+00) (0, 3.12817573547363281250e-01) (1, -1.08251404762268066406e+00) (2, -5.81473708152770996094e-01) (3, -2.06834721565246582031e+00) (0, 4.72255659103393554688e+00) (1, 2.08397698402404785156e+00) (2, 3.09458732604980468750e+00) (3, -1.00110316276550292969e+00) (0, -2.88788646459579467773e-01) (1, 6.22293472290039062500e-01) (2, 1.08450722694396972656e+00) (3, -9.10733461380004882812e-01) (0, 2.43448352813720703125e+00) (1, 1.47024786472320556641e+00) (2, 2.69755452871322631836e-01) (3, 3.18146944046020507812e+00) (0, -3.74824619293212890625e+00) (1, -9.68036293983459472656e-01) (2, -1.36479008197784423828e+00) (3, 3.57471913099288940430e-01) (0, -1.78631949424743652344e+00) (1, -2.04229307174682617188e+00) (2, -7.36254751682281494141e-01) (3, 5.87074875831604003906e-01) (0, -1.91515755653381347656e+00) (1, 6.31852924823760986328e-01) (2, -3.81243854761123657227e-01) (3, -2.16082668304443359375e+00) (0, -5.10606384277343750000e+00) (1, -2.64629149436950683594e+00) (2, -3.75593924522399902344e+00) (3, -2.58065009117126464844e+00) (4, -1.83525180816650390625e+00) (5, -1.43941426277160644531e+00) (6, -1.86354553699493408203e+00) (7, -2.33025997877120971680e-02) (8, 2.30595803260803222656e+00) (9, 1.43514525890350341797e+00) (10, -1.29169508814811706543e-01) (11, -7.81896471977233886719e-01) (12, 2.58428764343261718750e+00) (13, -9.55355614423751831055e-02) (14, -6.98705196380615234375e-01) (4, 1.95106434822082519531e+00) (5, 9.99532580375671386719e-01) (6, -4.61040943861007690430e-01) (7, -3.09784626960754394531e+00) (8, 2.64157700538635253906e+00) (9, -4.39960575103759765625e+00) (10, -2.65958714485168457031e+00) (11, -1.53401458263397216797e+00) (12, -1.28372535109519958496e-01) (13, -3.87419486045837402344e+00) (14, 1.46363580226898193359e+00) (4, 1.38639807701110839844e+00) (5, 2.26673439145088195801e-01) (6, 1.09813010692596435547e+00) (7, -2.88822007179260253906e+00) (8, 2.22569084167480468750e+00) (9, -4.20866155624389648438e+00) (10, -2.71688389778137207031e+00) (11, -2.02971482276916503906e+00) (12, -3.75992208719253540039e-01) (13, -4.10579586029052734375e+00) (14, 1.51062834262847900391e+00) 
