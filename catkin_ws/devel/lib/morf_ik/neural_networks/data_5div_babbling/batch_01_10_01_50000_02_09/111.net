FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.041367 0.001988 -0.134833 
scale_deviation_in=0.015361 0.011044 0.010385 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.497659 0.522024 -0.706589 
scale_deviation_out=0.278938 0.176611 0.155662 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.32916495203971862793e-01) (1, 1.19881343841552734375e+00) (2, 9.92841958999633789062e-01) (3, -3.29168051481246948242e-01) (0, 1.19415187835693359375e+00) (1, 1.84715956449508666992e-01) (2, 6.85752570629119873047e-01) (3, 5.23123264312744140625e-01) (0, 9.36121046543121337891e-01) (1, 2.98523426055908203125e-01) (2, -8.28284859657287597656e-01) (3, -7.95913457870483398438e-01) (0, 4.99666720628738403320e-01) (1, 1.04155695438385009766e+00) (2, -2.29738885536789894104e-03) (3, 5.22326171398162841797e-01) (0, -4.51620109379291534424e-02) (1, 1.48510441184043884277e-01) (2, -1.19410645961761474609e+00) (3, 4.03958093374967575073e-03) (0, 8.58206689357757568359e-01) (1, -1.47116243839263916016e+00) (2, 1.89460128545761108398e-01) (3, 1.05914378166198730469e+00) (0, 1.20586730539798736572e-01) (1, -3.41197431087493896484e-01) (2, 1.31576430797576904297e+00) (3, -1.32898628711700439453e-01) (0, 1.40752518177032470703e+00) (1, -1.92005053162574768066e-01) (2, -3.82916748523712158203e-01) (3, 3.66838306188583374023e-01) (0, -1.04004085063934326172e+00) (1, -8.21902334690093994141e-01) (2, 1.65934145450592041016e-01) (3, -7.31980800628662109375e-01) (0, 3.87535477057099342346e-03) (1, 3.56086306273937225342e-02) (2, -6.32666289806365966797e-01) (3, 1.04384757578372955322e-01) (4, 1.91518294811248779297e+00) (5, -2.40703001618385314941e-02) (6, 2.85161137580871582031e-01) (7, 1.22521150112152099609e+00) (8, 6.27979516983032226562e-01) (9, -2.16409564018249511719e+00) (10, -3.87209951877593994141e-01) (11, -5.81542253494262695312e-01) (12, -6.73103749752044677734e-01) (13, 1.65278136730194091797e-01) (14, 5.87401270866394042969e-01) (4, 5.38988173007965087891e-01) (5, 1.69474339485168457031e+00) (6, -2.52333879470825195312e-01) (7, -3.35507005453109741211e-01) (8, -1.15421783924102783203e+00) (9, -5.58629706501960754395e-02) (10, 1.62612903118133544922e+00) (11, 1.51730060577392578125e+00) (12, -9.54540729522705078125e-01) (13, -3.46957713365554809570e-01) (14, -7.06856012344360351562e-01) (4, 1.45894682407379150391e+00) (5, 1.04346108436584472656e+00) (6, -9.40718710422515869141e-01) (7, -1.18343420326709747314e-02) (8, -1.55077230930328369141e+00) (9, 7.12938964366912841797e-01) (10, 1.33597016334533691406e+00) (11, -1.06642627716064453125e+00) (12, 2.60577291250228881836e-01) (13, -5.00431051477789878845e-03) (14, -2.32684731483459472656e-01) 
