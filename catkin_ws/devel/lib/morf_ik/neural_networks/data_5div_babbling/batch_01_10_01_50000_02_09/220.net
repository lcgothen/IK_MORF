FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.095406 0.045394 -0.172905 
scale_deviation_in=0.015069 0.014380 0.010152 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.126580 0.200131 -1.673695 
scale_deviation_out=0.136101 0.183419 0.275473 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.96077877283096313477e-01) (1, 3.91649007797241210938e-01) (2, 5.03989338874816894531e-01) (3, -1.09784379601478576660e-01) (0, 6.80963099002838134766e-01) (1, -7.52938687801361083984e-01) (2, -8.54454219341278076172e-01) (3, 3.00278127193450927734e-01) (0, 7.99353361129760742188e-01) (1, 7.70671844482421875000e-01) (2, 1.33514001965522766113e-01) (3, -4.47199523448944091797e-01) (0, 9.25550520420074462891e-01) (1, -1.07443928718566894531e+00) (2, -3.09885084629058837891e-01) (3, 6.34944558143615722656e-01) (0, 4.48867082595825195312e-01) (1, -3.24247181415557861328e-01) (2, 9.99559581279754638672e-01) (3, -4.34111177921295166016e-01) (0, -6.15253269672393798828e-01) (1, -1.90380409359931945801e-01) (2, 1.87678456306457519531e+00) (3, 9.24422815442085266113e-02) (0, 3.08657884597778320312e-01) (1, 6.50733947753906250000e-01) (2, -7.88059830665588378906e-01) (3, -1.65329739451408386230e-01) (0, -6.00426673889160156250e-01) (1, 1.18001270294189453125e+00) (2, -3.11372876167297363281e-02) (3, 7.58313536643981933594e-01) (0, -6.26877665519714355469e-01) (1, -2.62688517570495605469e-01) (2, 2.26293593645095825195e-01) (3, -6.41368150711059570312e-01) (0, -3.81179228425025939941e-02) (1, 9.32806968688964843750e-01) (2, -8.79218399524688720703e-01) (3, -6.05052292346954345703e-01) (4, 6.15628838539123535156e-01) (5, -9.19687330722808837891e-01) (6, 4.67483997344970703125e-01) (7, -1.67930960655212402344e+00) (8, -2.77121722698211669922e-01) (9, -2.72101163864135742188e-01) (10, 9.42045822739601135254e-03) (11, 1.11463320255279541016e+00) (12, 7.29251140728592872620e-03) (13, 1.16851854324340820312e+00) (14, 5.36316335201263427734e-01) (4, 6.52913987636566162109e-01) (5, -7.69470453262329101562e-01) (6, 6.68514549732208251953e-01) (7, -9.03689324855804443359e-01) (8, 1.05282104015350341797e+00) (9, 1.59633922576904296875e+00) (10, -6.87166869640350341797e-01) (11, -7.10695505142211914062e-01) (12, -3.38372617959976196289e-01) (13, -8.52972686290740966797e-01) (14, 5.90993225574493408203e-01) (4, 8.89440551400184631348e-02) (5, -6.51877105236053466797e-01) (6, -9.80374217033386230469e-01) (7, -6.66074976325035095215e-02) (8, 2.94035702943801879883e-01) (9, 1.74838995933532714844e+00) (10, -5.36194205284118652344e-01) (11, 6.49589180946350097656e-01) (12, 7.12668836116790771484e-01) (13, -1.12364506721496582031e+00) (14, -2.10596457123756408691e-01) 
