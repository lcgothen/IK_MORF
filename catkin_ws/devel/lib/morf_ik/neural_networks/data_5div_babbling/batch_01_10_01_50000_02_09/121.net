FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.049934 0.037877 -0.135244 
scale_deviation_in=0.013191 0.012506 0.010525 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.920533 0.656272 -0.748030 
scale_deviation_out=0.138142 0.168299 0.164212 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.21631944179534912109e-01) (1, 1.37845531105995178223e-01) (2, 4.93564516305923461914e-01) (3, -3.29621918499469757080e-02) (0, 9.71847772598266601562e-01) (1, -5.99409341812133789062e-01) (2, 1.11052548885345458984e+00) (3, 4.55713756382465362549e-02) (0, -8.52085351943969726562e-01) (1, -2.85265028476715087891e-01) (2, 6.20553493499755859375e-01) (3, -9.25669848918914794922e-01) (0, -1.52213692665100097656e+00) (1, 5.49477189779281616211e-02) (2, -4.66988205909729003906e-01) (3, -3.13170552253723144531e-01) (0, 1.05484104156494140625e+00) (1, -1.51406610012054443359e+00) (2, -6.01077497005462646484e-01) (3, -7.11336612701416015625e-01) (0, 5.73395609855651855469e-01) (1, -8.11611711978912353516e-01) (2, 3.16837914288043975830e-02) (3, -5.83068549633026123047e-01) (0, 1.98881119489669799805e-01) (1, 3.23817223310470581055e-01) (2, -1.45858466625213623047e+00) (3, -6.45955324172973632812e-01) (0, 5.29986381530761718750e-01) (1, -1.28600811958312988281e+00) (2, 7.35375165939331054688e-01) (3, -1.76092267036437988281e-01) (0, 5.94043672084808349609e-01) (1, -1.31370949745178222656e+00) (2, -1.19446837902069091797e+00) (3, 2.33864679932594299316e-01) (0, 3.05062800645828247070e-01) (1, -1.74865081906318664551e-01) (2, -3.69996279478073120117e-01) (3, 1.01724493503570556641e+00) (4, -4.07150238752365112305e-02) (5, -1.22687625885009765625e+00) (6, 8.65513384342193603516e-01) (7, 7.18709945678710937500e-01) (8, -1.93447756767272949219e+00) (9, -1.17065715789794921875e+00) (10, 3.88793230056762695312e-01) (11, -1.64299452304840087891e+00) (12, -1.61807882785797119141e+00) (13, 3.36154662072658538818e-02) (14, -4.57541346549987792969e-01) (4, 4.79928672313690185547e-01) (5, 1.01562070846557617188e+00) (6, -1.88549950718879699707e-01) (7, -2.17016768455505371094e+00) (8, 4.14508059620857238770e-02) (9, -4.41026389598846435547e-02) (10, -1.43637776374816894531e+00) (11, -3.00509572029113769531e-01) (12, -1.76315534114837646484e+00) (13, 2.69609782844781875610e-02) (14, -6.07196092605590820312e-01) (4, 5.81919074058532714844e-01) (5, 8.85490894317626953125e-01) (6, 4.86688949167728424072e-02) (7, 7.56259024143218994141e-01) (8, -7.81836390495300292969e-01) (9, 1.12671844661235809326e-01) (10, -1.98349404335021972656e+00) (11, 1.76620769500732421875e+00) (12, -8.12522232532501220703e-01) (13, -6.65511667728424072266e-01) (14, -9.23074036836624145508e-02) 
