FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.156192 0.100174 0.045802 
scale_deviation_in=0.013585 0.014191 0.010486 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.000138 1.924447 -1.449605 
scale_deviation_out=0.084284 0.250131 0.366072 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.54949569702148437500e+00) (1, 2.27597103118896484375e+01) (2, 2.67335128784179687500e+00) (3, -2.48292851448059082031e+00) (0, -1.68123359680175781250e+01) (1, -1.15612564086914062500e+01) (2, -3.48659181594848632812e+00) (3, -2.03751068115234375000e+01) (0, 3.01345024108886718750e+01) (1, 1.96242446899414062500e+01) (2, 7.42719888687133789062e+00) (3, -2.30348320007324218750e+01) (0, 2.49163131713867187500e+01) (1, -6.33404111862182617188e+00) (2, 3.20804214477539062500e+00) (3, -2.41272711753845214844e+00) (0, 1.65302028656005859375e+01) (1, 1.15234708786010742188e+01) (2, 2.96175837516784667969e+00) (3, 1.99774456024169921875e+01) (0, 2.24346904754638671875e+01) (1, 1.45215301513671875000e+01) (2, 5.97793054580688476562e+00) (3, -1.90795993804931640625e+01) (0, 1.46066350936889648438e+01) (1, 1.19976587295532226562e+01) (2, 3.01764154434204101562e+00) (3, 1.90189113616943359375e+01) (0, -1.87452659606933593750e+01) (1, -1.16700859069824218750e+01) (2, -3.67540025711059570312e+00) (3, -2.22424163818359375000e+01) (0, 1.57888717651367187500e+01) (1, 1.10365591049194335938e+01) (2, 4.30486869812011718750e+00) (3, 1.96864109039306640625e+01) (0, 3.11431465148925781250e+01) (1, 2.03652515411376953125e+01) (2, 7.76348304748535156250e+00) (3, -2.36530780792236328125e+01) (4, 2.00079250335693359375e+00) (5, 6.60893857479095458984e-01) (6, -1.55733540654182434082e-01) (7, -1.90979087352752685547e+00) (8, -3.40206325054168701172e-01) (9, 6.98831379413604736328e-02) (10, 4.47174882888793945312e+00) (11, 3.16737985610961914062e+00) (12, -1.44139647483825683594e-01) (13, 1.08136415481567382812e-01) (14, -1.53032448142766952515e-02) (4, -2.60475692749023437500e+01) (5, 2.26397819519042968750e+01) (6, -4.84465866088867187500e+01) (7, -2.61018848419189453125e+01) (8, -2.36321372985839843750e+01) (9, -3.78238410949707031250e+01) (10, -2.10856685638427734375e+01) (11, 2.37982044219970703125e+01) (12, -2.04746894836425781250e+01) (13, -4.93629989624023437500e+01) (14, -2.37525482177734375000e+01) (4, -2.70160408020019531250e+01) (5, 2.24326152801513671875e+01) (6, -4.83515434265136718750e+01) (7, -2.70388698577880859375e+01) (8, -2.14396362304687500000e+01) (9, -4.08328781127929687500e+01) (10, -2.13804588317871093750e+01) (11, 2.35007572174072265625e+01) (12, -2.38322849273681640625e+01) (13, -4.99935607910156250000e+01) (14, -2.63323822021484375000e+01) 
