FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.186943 -0.003014 -0.130703 
scale_deviation_in=0.006163 0.014513 0.007982 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.586773 0.229644 -2.421431 
scale_deviation_out=0.077478 0.212626 0.327796 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -5.77133357524871826172e-01) (1, -2.65459823608398437500e+00) (2, 4.98271048069000244141e-01) (3, -3.85908102989196777344e+00) (0, 6.06322824954986572266e-01) (1, -4.73338365554809570312e-01) (2, -4.23158764839172363281e-01) (3, 3.63288640975952148438e-01) (0, -1.80072307586669921875e+00) (1, -1.69905662536621093750e+00) (2, 9.12961363792419433594e-01) (3, -4.10850077867507934570e-01) (0, 1.84673666954040527344e+00) (1, -1.93195772171020507812e+00) (2, -1.12701511383056640625e+00) (3, 7.69941091537475585938e-01) (0, -5.78023052215576171875e+00) (1, 2.24052160978317260742e-01) (2, 4.27402210235595703125e+00) (3, -3.47895479202270507812e+00) (0, -4.70985054969787597656e-01) (1, 2.36271119117736816406e+00) (2, 5.68778336048126220703e-01) (3, -3.98006772994995117188e+00) (0, -3.22793990373611450195e-01) (1, 1.76423028111457824707e-01) (2, -1.02015614509582519531e+00) (3, -2.75997304916381835938e+00) (0, -3.55831950902938842773e-01) (1, -3.61393034458160400391e-01) (2, 3.73723238706588745117e-01) (3, -1.35473465919494628906e+00) (0, -2.17381849884986877441e-01) (1, 2.94071078300476074219e-01) (2, 1.60358279943466186523e-01) (3, -1.89412355422973632812e+00) (0, -5.01929104328155517578e-01) (1, 6.84298798441886901855e-02) (2, -6.02267324924468994141e-01) (3, 4.03556495904922485352e-01) (4, -3.35771226882934570312e+00) (5, -1.63175940513610839844e+00) (6, -1.19399964809417724609e+00) (7, -7.93728947639465332031e-01) (8, -7.04514607787132263184e-02) (9, 3.34333324432373046875e+00) (10, 2.27389372885227203369e-02) (11, -1.69440639019012451172e+00) (12, 1.24361276626586914062e+00) (13, 1.13653704524040222168e-01) (14, 2.28876829147338867188e-01) (4, -1.52553009986877441406e+00) (5, 1.49987173080444335938e+00) (6, 1.01399540901184082031e+00) (7, -1.77774643898010253906e+00) (8, 1.04564437866210937500e+01) (9, -2.44317269325256347656e+00) (10, -3.58572578430175781250e+00) (11, -1.14780259132385253906e+00) (12, -1.04825878143310546875e+00) (13, -1.26927649974822998047e+00) (14, 2.28022933006286621094e+00) (4, -1.62130665779113769531e+00) (5, 3.11350524425506591797e-01) (6, 1.18933093547821044922e+00) (7, -1.49587428569793701172e+00) (8, 1.11594047546386718750e+01) (9, -2.74650526046752929688e+00) (10, -2.83906769752502441406e+00) (11, -1.85166668891906738281e+00) (12, -2.04702591896057128906e+00) (13, -3.39544922113418579102e-01) (14, 2.14922237396240234375e+00) 
