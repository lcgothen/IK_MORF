FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.181331 0.128279 -0.059679 
scale_deviation_in=0.003408 0.004912 0.009841 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.955078 0.561082 -2.570754 
scale_deviation_out=0.023315 0.196971 0.299696 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -4.10733699798583984375e+00) (1, -3.36646735668182373047e-01) (2, 1.85368156433105468750e+00) (3, -2.87134695053100585938e+00) (0, 2.33146643638610839844e+00) (1, -2.06433629989624023438e+00) (2, -1.09381568431854248047e+00) (3, 3.70884585380554199219e+00) (0, 1.46435940265655517578e+00) (1, 3.08659529685974121094e+00) (2, -4.16151404380798339844e-01) (3, 2.19133305549621582031e+00) (0, -1.24803078174591064453e+00) (1, 1.71306407451629638672e+00) (2, -3.52816104888916015625e-01) (3, -2.63151097297668457031e+00) (0, -8.53366076946258544922e-01) (1, 2.94808112084865570068e-03) (2, 3.85157108306884765625e-01) (3, 1.21986262500286102295e-01) (0, 2.81399209052324295044e-02) (1, 8.60251188278198242188e-01) (2, -1.46126914024353027344e+00) (3, 2.98704719543457031250e+00) (0, 2.60318374633789062500e+00) (1, 2.10730099678039550781e+00) (2, -1.30659067630767822266e+00) (3, 1.15203988552093505859e+00) (0, 7.55364239215850830078e-01) (1, -2.63170301914215087891e-02) (2, -3.45228344202041625977e-01) (3, -6.70159161090850830078e-01) (0, -1.60226345062255859375e-01) (1, -7.38117098808288574219e-01) (2, 3.96353080868721008301e-02) (3, -9.62213724851608276367e-02) (0, 1.10928559303283691406e+00) (1, -1.00382614135742187500e+00) (2, -1.58336591720581054688e+00) (3, -3.59017896652221679688e+00) (4, 1.04121631011366844177e-02) (5, -3.41322708129882812500e+00) (6, -1.53015553951263427734e+00) (7, 2.22893142700195312500e+00) (8, 7.27885484695434570312e-01) (9, 2.69434905052185058594e+00) (10, 1.49669229984283447266e+00) (11, -1.04676294326782226562e+00) (12, -2.24298620223999023438e+00) (13, -1.61268854141235351562e+00) (14, 5.77446043491363525391e-01) (4, 3.04082846641540527344e+00) (5, 1.76570081710815429688e+00) (6, -2.75096535682678222656e+00) (7, -1.07654488086700439453e+00) (8, 1.07566487789154052734e+00) (9, -2.45433402061462402344e+00) (10, 4.02423906326293945312e+00) (11, -1.18503785133361816406e+00) (12, 3.45667265355587005615e-02) (13, -2.21058440208435058594e+00) (14, -4.16674196720123291016e-01) (4, 3.00145411491394042969e+00) (5, 2.64330673217773437500e+00) (6, -2.69231700897216796875e+00) (7, 1.34546693880110979080e-03) (8, 1.42021632194519042969e+00) (9, -1.16593825817108154297e+00) (10, 3.88032341003417968750e+00) (11, -9.84374463558197021484e-01) (12, 5.88585913181304931641e-01) (13, -1.27095186710357666016e+00) (14, -5.51423072814941406250e-01) 
