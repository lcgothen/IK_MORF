FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.162312 0.048498 0.006876 
scale_deviation_in=0.008922 0.014520 0.010365 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.280632 2.073713 -0.921641 
scale_deviation_out=0.087723 0.107297 0.144668 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.69199275970458984375e+00) (1, 3.01951497793197631836e-01) (2, -7.01692581176757812500e-01) (3, -4.57806587219238281250e-01) (0, 2.23096683621406555176e-01) (1, 1.36753880977630615234e+00) (2, -4.73672717809677124023e-01) (3, 3.90995889902114868164e-01) (0, -9.28538918495178222656e-01) (1, 6.68311268091201782227e-02) (2, -9.98608171939849853516e-01) (3, 4.17789191007614135742e-01) (0, 8.86702299118041992188e-01) (1, -6.32544398307800292969e-01) (2, -6.64688885211944580078e-01) (3, 1.21598348021507263184e-01) (0, 2.45126988738775253296e-02) (1, 1.54110038280487060547e+00) (2, 9.27475988864898681641e-01) (3, 1.29947677254676818848e-01) (0, 7.29330420494079589844e-01) (1, -1.62889674305915832520e-01) (2, 1.10073852539062500000e+00) (3, 4.35020595788955688477e-01) (0, -1.28287076950073242188e+00) (1, -9.78008866310119628906e-01) (2, 3.45969170331954956055e-01) (3, 4.92746829986572265625e-01) (0, -1.44372045993804931641e+00) (1, -3.78314942121505737305e-01) (2, 6.23793423175811767578e-01) (3, -5.96863925457000732422e-01) (0, 9.40009206533432006836e-02) (1, 5.78927338123321533203e-01) (2, -8.98931503295898437500e-01) (3, 9.49926972389221191406e-01) (0, 7.72848308086395263672e-01) (1, -9.93369519710540771484e-01) (2, 2.64355748891830444336e-01) (3, -4.99607354402542114258e-01) (4, 1.56690955162048339844e-01) (5, 1.22521686553955078125e+00) (6, 7.17427372932434082031e-01) (7, -4.84346479177474975586e-01) (8, 1.84901273250579833984e+00) (9, -5.84792673587799072266e-01) (10, -1.05706369876861572266e+00) (11, 6.86164855957031250000e-01) (12, -4.11091625690460205078e-01) (13, -1.20009374618530273438e+00) (14, -5.35319233313202857971e-03) (4, -1.90306448936462402344e+00) (5, 1.37157604098320007324e-01) (6, 2.48980835080146789551e-01) (7, -2.28127747774124145508e-01) (8, -7.16307282447814941406e-01) (9, 4.36218798160552978516e-01) (10, 9.71920251846313476562e-01) (11, 1.62496316432952880859e+00) (12, -1.03691399097442626953e+00) (13, -5.76037876307964324951e-02) (14, 1.58982723951339721680e-01) (4, -8.76839816570281982422e-01) (5, -6.49654209613800048828e-01) (6, 1.11556744575500488281e+00) (7, -1.34080469608306884766e-01) (8, -1.00197947025299072266e+00) (9, -7.86496579647064208984e-01) (10, 1.27955973148345947266e+00) (11, 8.13186943531036376953e-01) (12, 7.02908396720886230469e-01) (13, -4.42325532436370849609e-01) (14, -4.36596900224685668945e-01) 
