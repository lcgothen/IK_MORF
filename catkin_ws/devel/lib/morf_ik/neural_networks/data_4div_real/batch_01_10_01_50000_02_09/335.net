FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.188441 0.121181 0.036280 
scale_deviation_in=0.001666 0.003139 0.004374 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.996836 1.253027 -2.041400 
scale_deviation_out=0.011720 0.159894 0.552858 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.59686088562011718750e+00) (1, 5.34906768798828125000e+00) (2, 4.35556983947753906250e+00) (3, 4.25751590728759765625e+00) (0, 1.05915918946266174316e-01) (1, -3.71388316154479980469e+00) (2, 2.64308810234069824219e-01) (3, 1.85916161537170410156e+00) (0, 1.64755845069885253906e+00) (1, -8.57607603073120117188e-01) (2, -1.88477784395217895508e-01) (3, -9.92308437824249267578e-01) (0, 1.43939340114593505859e+00) (1, -9.11535072326660156250e+00) (2, 3.70168954133987426758e-01) (3, -5.98369264602661132812e+00) (0, 3.89887666702270507812e+00) (1, -5.68270826339721679688e+00) (2, -1.61636662483215332031e+00) (3, 1.61324751377105712891e+00) (0, -1.15973463058471679688e+01) (1, 9.56591904163360595703e-01) (2, -1.08667478561401367188e+01) (3, -2.45426797866821289062e+00) (0, 5.67341899871826171875e+00) (1, -3.63777709007263183594e+00) (2, -2.27915644645690917969e+00) (3, -3.67651510238647460938e+00) (0, -3.56616473197937011719e+00) (1, -2.84542894363403320312e+00) (2, 2.87441194057464599609e-01) (3, -4.01361751556396484375e+00) (0, -2.39828228950500488281e+00) (1, -6.30348300933837890625e+00) (2, 1.62309324741363525391e+00) (3, -6.07802331447601318359e-01) (0, 3.79065155982971191406e+00) (1, -1.05582761764526367188e+00) (2, 2.80873465538024902344e+00) (3, 1.51093268394470214844e+00) (4, 1.43027019500732421875e+01) (5, -9.86574649810791015625e+00) (6, -1.32333488464355468750e+01) (7, -7.45651245117187500000e+00) (8, -1.35773525238037109375e+01) (9, 7.90142440795898437500e+00) (10, -9.84237957000732421875e+00) (11, -1.00771675109863281250e+01) (12, -1.34518661499023437500e+01) (13, -1.26549081802368164062e+01) (14, 1.40282087326049804688e+01) (4, 7.12128877639770507812e+00) (5, 1.89556920528411865234e+00) (6, -2.91837501525878906250e+00) (7, -7.63790845870971679688e+00) (8, 1.14178848266601562500e+00) (9, 4.62704658508300781250e+00) (10, 4.38005876541137695312e+00) (11, 5.32714700698852539062e+00) (12, 3.68250203132629394531e+00) (13, 3.81043255329132080078e-01) (14, -5.53621959686279296875e+00) (4, -3.73224449157714843750e+00) (5, 1.88746201992034912109e+00) (6, 1.27510511875152587891e+00) (7, -7.75253582000732421875e+00) (8, -6.63186788558959960938e-01) (9, -6.01900768280029296875e+00) (10, -4.21048450469970703125e+00) (11, 3.11179637908935546875e+00) (12, -2.25230312347412109375e+00) (13, -3.66961479187011718750e+00) (14, -2.35974478721618652344e+00) 
