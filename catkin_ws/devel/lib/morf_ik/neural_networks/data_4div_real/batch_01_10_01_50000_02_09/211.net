FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.151466 0.015895 -0.116662 
scale_deviation_in=0.017849 0.019074 0.012260 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.451800 1.666980 -1.003553 
scale_deviation_out=0.128925 0.222919 0.742842 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -2.18053907155990600586e-01) (1, 2.00274869799613952637e-01) (2, 7.28957295417785644531e-01) (3, 8.74476432800292968750e-01) (0, -1.82534128427505493164e-01) (1, -6.27249300479888916016e-01) (2, 6.53818488121032714844e-01) (3, -5.94559252262115478516e-01) (0, 7.94288456439971923828e-01) (1, 6.67810976505279541016e-01) (2, -1.96895748376846313477e-01) (3, 1.01950657367706298828e+00) (0, 1.31653320789337158203e+00) (1, 2.87962015718221664429e-02) (2, 3.60981971025466918945e-01) (3, -8.54555428028106689453e-01) (0, 3.29608529806137084961e-01) (1, 4.12500798702239990234e-01) (2, 1.17417991161346435547e+00) (3, 1.31939262151718139648e-01) (0, 1.10494613647460937500e+00) (1, -3.08606058359146118164e-01) (2, -6.06513619422912597656e-01) (3, 1.56052887439727783203e+00) (0, 9.40970405936241149902e-02) (1, -1.28041112422943115234e+00) (2, 1.55973151326179504395e-01) (3, 1.63718664646148681641e+00) (0, 4.16243016719818115234e-01) (1, 2.66655969619750976562e+00) (2, -1.03818491101264953613e-01) (3, 4.13130712509155273438e+00) (0, -5.48535943031311035156e-01) (1, 5.94016969203948974609e-01) (2, -4.35612022876739501953e-01) (3, -1.07277631759643554688e+00) (0, 4.63133417069911956787e-02) (1, 1.18988290429115295410e-01) (2, -9.37473833560943603516e-01) (3, 1.22687304019927978516e+00) (4, 9.02685642242431640625e-01) (5, -1.64609658718109130859e+00) (6, 1.85661602020263671875e+00) (7, -3.37081521749496459961e-01) (8, 6.89326226711273193359e-01) (9, -1.55536031723022460938e+00) (10, -2.32926106452941894531e+00) (11, 2.33226656913757324219e+00) (12, 1.86351239681243896484e+00) (13, -5.16971528530120849609e-01) (14, -3.81404876708984375000e-01) (4, 1.93427205085754394531e+00) (5, 1.29492914676666259766e+00) (6, -8.94654512405395507812e-01) (7, -2.47750067710876464844e+00) (8, 9.63999211788177490234e-01) (9, -1.49459815025329589844e+00) (10, -4.19368624687194824219e-01) (11, 8.84109675884246826172e-01) (12, -1.60486817359924316406e+00) (13, -1.54920732975006103516e+00) (14, -4.50132220983505249023e-01) (4, 1.32373416423797607422e+00) (5, -9.29345667362213134766e-01) (6, 4.72441881895065307617e-01) (7, -7.64963805675506591797e-01) (8, 9.08381789922714233398e-02) (9, 9.50141072273254394531e-01) (10, 8.53821575641632080078e-01) (11, -1.50247454643249511719e+00) (12, 5.58243095874786376953e-01) (13, -5.68241596221923828125e-01) (14, -4.11983251571655273438e-01) 
