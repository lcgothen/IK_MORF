FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.182222 -0.045987 0.061166 
scale_deviation_in=0.002807 0.011537 0.008231 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.819706 2.143573 -1.638824 
scale_deviation_out=0.066741 0.060661 0.199684 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.55505466461181640625e+00) (1, -3.16876173019409179688e-01) (2, 2.83915543556213378906e+00) (3, -2.96814179420471191406e+00) (0, -7.73505270481109619141e-01) (1, -3.00258374214172363281e+00) (2, -1.05769300460815429688e+00) (3, 3.49681138992309570312e+00) (0, -7.26512312889099121094e-01) (1, 1.48183691501617431641e+00) (2, -7.31682658195495605469e-01) (3, 1.25043392181396484375e+00) (0, -2.92365884780883789062e+00) (1, -1.76978242397308349609e+00) (2, -3.34424781799316406250e+00) (3, 2.31295776367187500000e+00) (0, -1.52095139026641845703e+00) (1, 6.17287993431091308594e-01) (2, 2.46356821060180664062e+00) (3, -1.38394641876220703125e+00) (0, -5.02341079711914062500e+00) (1, 1.68454384803771972656e+00) (2, 8.78880310058593750000e+00) (3, -4.36080312728881835938e+00) (0, -1.96130901575088500977e-01) (1, 4.49365615844726562500e+00) (2, -3.82072359323501586914e-01) (3, -4.15569257736206054688e+00) (0, 2.95223402976989746094e+00) (1, 4.26006674766540527344e-01) (2, 2.95445227622985839844e+00) (3, -2.04676747322082519531e+00) (0, -1.14744067192077636719e+00) (1, -7.60301947593688964844e-01) (2, -1.14723157882690429688e+00) (3, -1.80149364471435546875e+00) (0, -8.83569061756134033203e-01) (1, -3.68710732460021972656e+00) (2, -8.59294652938842773438e-01) (3, 1.10794758796691894531e+00) (4, -2.12577080726623535156e+00) (5, -3.95880651473999023438e+00) (6, 4.82179403305053710938e+00) (7, -2.93975543975830078125e+00) (8, -2.80184447765350341797e-01) (9, 1.79970383644104003906e-01) (10, 6.29976034164428710938e+00) (11, 1.20419628918170928955e-01) (12, -3.25699377059936523438e+00) (13, 2.89981126785278320312e+00) (14, 4.12801122665405273438e+00) (4, -3.63595962524414062500e+00) (5, -2.77055382728576660156e+00) (6, 3.29076194763183593750e+00) (7, 4.98377943038940429688e+00) (8, 1.36902427673339843750e+00) (9, -9.08558011054992675781e-01) (10, 2.69166421890258789062e+00) (11, -4.55987501144409179688e+00) (12, 1.53641223907470703125e+00) (13, -2.77249431610107421875e+00) (14, -4.25268125534057617188e+00) (4, -3.48693251609802246094e+00) (5, 3.67710947990417480469e+00) (6, 2.10436984896659851074e-01) (7, 2.74902439117431640625e+00) (8, -4.59996891021728515625e+00) (9, 3.65947055816650390625e+00) (10, 3.08209609985351562500e+00) (11, 4.14036893844604492188e+00) (12, 4.18983554840087890625e+00) (13, -2.04485607147216796875e+00) (14, 5.05580127239227294922e-01) 
