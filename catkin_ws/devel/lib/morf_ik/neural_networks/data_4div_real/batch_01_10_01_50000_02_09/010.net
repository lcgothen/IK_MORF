FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.040962 0.011187 -0.149332 
scale_deviation_in=0.013043 0.017723 0.008230 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.283319 1.174548 -0.928671 
scale_deviation_out=0.342447 0.159710 0.444546 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -9.59952056407928466797e-01) (1, -3.08877695351839065552e-03) (2, 1.70934185385704040527e-01) (3, -1.44154798984527587891e+00) (0, 9.77715849876403808594e-01) (1, -2.26154756546020507812e+00) (2, -1.65258795022964477539e-01) (3, 3.21143627166748046875e+00) (0, 5.22785961627960205078e-01) (1, -2.16151654720306396484e-01) (2, 1.24424338340759277344e+00) (3, -1.17595124244689941406e+00) (0, -2.65627384185791015625e-01) (1, -9.70886993408203125000e+00) (2, 2.09657162427902221680e-01) (3, -1.02624845504760742188e+01) (0, -5.85238635540008544922e-02) (1, 7.43582174181938171387e-02) (2, -1.00307738780975341797e+00) (3, 5.13161599636077880859e-01) (0, 8.55331718921661376953e-01) (1, 2.15743279457092285156e+00) (2, 3.63048762083053588867e-01) (3, 1.95132172107696533203e+00) (0, 8.00340235233306884766e-01) (1, 7.00475573539733886719e-01) (2, 9.16120707988739013672e-01) (3, -1.82409858703613281250e+00) (0, -4.68791544437408447266e-01) (1, 4.02927219867706298828e-01) (2, -2.91030369699001312256e-02) (3, -1.23931324481964111328e+00) (0, -1.07348775863647460938e+00) (1, 8.77487242221832275391e-01) (2, -3.36098372936248779297e-01) (3, -1.25775098800659179688e+00) (0, 1.82842597365379333496e-01) (1, 4.07906696200370788574e-02) (2, -7.32271909713745117188e-01) (3, -1.02401399612426757812e+00) (4, 7.51681149005889892578e-01) (5, -4.54511976242065429688e+00) (6, -6.38135194778442382812e-01) (7, -7.33961105346679687500e+00) (8, -1.50028541684150695801e-01) (9, 1.72584819793701171875e+00) (10, 1.27789497375488281250e+00) (11, 1.37480187416076660156e+00) (12, 1.55632460117340087891e+00) (13, 6.08490943908691406250e-01) (14, -1.18579232692718505859e+00) (4, -2.12093162536621093750e+00) (5, -1.58906412124633789062e+00) (6, 2.13993406295776367188e+00) (7, 9.15003001689910888672e-01) (8, -5.79399406909942626953e-01) (9, 1.39113855361938476562e+00) (10, 2.84019136428833007812e+00) (11, -2.35883545875549316406e+00) (12, -8.35318386554718017578e-01) (13, -2.81161594390869140625e+00) (14, 1.65883749723434448242e-01) (4, -6.00477904081344604492e-02) (5, 1.17295193672180175781e+00) (6, -1.72723621129989624023e-01) (7, 6.19732475280761718750e+00) (8, -1.41264036297798156738e-01) (9, 2.62350887060165405273e-01) (10, -1.32910460233688354492e-01) (11, -1.44552350044250488281e+00) (12, 7.42353796958923339844e-01) (13, 2.80857831239700317383e-01) (14, 3.85600185394287109375e+00) 
