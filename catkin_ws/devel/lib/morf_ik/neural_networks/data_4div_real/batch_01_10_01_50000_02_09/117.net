FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.094169 0.016688 0.144705 
scale_deviation_in=0.017794 0.019121 0.005712 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.392590 1.982441 -2.253578 
scale_deviation_out=0.207038 0.159032 0.482734 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.29239201545715332031e+00) (1, -1.71990549564361572266e+00) (2, 7.51552462577819824219e-01) (3, 2.63854837417602539062e+00) (0, 4.51157659292221069336e-01) (1, -6.18300199508666992188e-01) (2, -1.75970062613487243652e-01) (3, 5.43612480163574218750e-01) (0, 5.88792276382446289062e+00) (1, 1.44494986534118652344e+00) (2, 3.55362296104431152344e+00) (3, -3.55186551809310913086e-01) (0, -4.08860743045806884766e-01) (1, 1.68220782279968261719e+00) (2, 7.39925682544708251953e-01) (3, -3.03605365753173828125e+00) (0, -5.59635400772094726562e-01) (1, -5.99960517883300781250e+00) (2, -1.03065989911556243896e-01) (3, -6.98189449310302734375e+00) (0, 8.42435538768768310547e-01) (1, -2.55916118621826171875e-01) (2, -1.44063484668731689453e+00) (3, 1.86313569545745849609e+00) (0, -2.03216719627380371094e+00) (1, -1.11099958419799804688e+00) (2, -1.41979014873504638672e+00) (3, -2.71586656570434570312e+00) (0, 8.69836688041687011719e-01) (1, -5.56121289730072021484e-01) (2, 4.44386266171932220459e-02) (3, 1.72502160072326660156e+00) (0, -9.80216979980468750000e-01) (1, -2.73609113693237304688e+00) (2, -4.00525867938995361328e-01) (3, -2.54394960403442382812e+00) (0, 1.53924107551574707031e-01) (1, 3.89204353094100952148e-01) (2, -1.13378345966339111328e+00) (3, 1.17656421661376953125e+00) (4, -3.30258393287658691406e+00) (5, -9.78981554508209228516e-01) (6, 1.33793815970420837402e-01) (7, 2.81185531616210937500e+00) (8, -5.06199312210083007812e+00) (9, -2.10247918963432312012e-01) (10, -1.54244804382324218750e+00) (11, -1.41907727718353271484e+00) (12, -4.31769877672195434570e-01) (13, 1.30133664608001708984e+00) (14, -6.79694473743438720703e-01) (4, -2.76887744665145874023e-01) (5, -3.69088277220726013184e-02) (6, 2.96086668968200683594e+00) (7, 1.40051949024200439453e+00) (8, 1.17790684103965759277e-01) (9, -3.05958390235900878906e+00) (10, -1.67185175418853759766e+00) (11, 8.97823393344879150391e-01) (12, 9.07128274440765380859e-01) (13, -2.87786102294921875000e+00) (14, 2.74889397621154785156e+00) (4, -2.15887531638145446777e-01) (5, 4.52690362930297851562e-01) (6, 3.20828408002853393555e-01) (7, 2.13704228401184082031e-01) (8, -3.50326752662658691406e+00) (9, -1.13669537007808685303e-01) (10, -1.62243819236755371094e+00) (11, -1.56761002540588378906e+00) (12, 1.68261551856994628906e+00) (13, 1.96739569306373596191e-01) (14, -1.96204936504364013672e+00) 
