FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.185314 -0.047579 -0.008926 
scale_deviation_in=0.000336 0.013094 0.002986 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.825897 2.186189 -0.986002 
scale_deviation_out=0.067861 0.023507 0.168847 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.69463646411895751953e+00) (1, -1.93004906177520751953e+00) (2, 9.12832796573638916016e-01) (3, -1.13395810127258300781e+00) (0, 1.22664678096771240234e+00) (1, -6.34809541702270507812e+00) (2, -2.18380808830261230469e+00) (3, 1.36580288410186767578e+00) (0, -2.86198973655700683594e+00) (1, 2.97010970115661621094e+00) (2, -4.81684970855712890625e+00) (3, 2.12684011459350585938e+00) (0, 2.00129532814025878906e+00) (1, -2.55041527748107910156e+00) (2, 6.36839687824249267578e-01) (3, -1.92885029315948486328e+00) (0, -1.52039301395416259766e+00) (1, -1.16469526290893554688e+00) (2, 4.70640563964843750000e+00) (3, 2.91053026914596557617e-01) (0, 3.26183986663818359375e+00) (1, -3.84986257553100585938e+00) (2, -8.38105392456054687500e+00) (3, -7.75258111953735351562e+00) (0, 1.12499451637268066406e+00) (1, 6.98167324066162109375e+00) (2, -4.79001581668853759766e-01) (3, 1.25418341159820556641e+00) (0, -5.56622922420501708984e-01) (1, 2.11178755760192871094e+00) (2, 8.32020342350006103516e-02) (3, 1.38520586490631103516e+00) (0, 2.60096788406372070312e+00) (1, 2.02555108070373535156e+00) (2, 4.17932569980621337891e-01) (3, 1.81299996376037597656e+00) (0, 1.53380423784255981445e-01) (1, 7.48715496063232421875e+00) (2, -7.89688408374786376953e-01) (3, -1.70929419994354248047e+00) (4, -8.50506496429443359375e+00) (5, -1.04248409271240234375e+01) (6, 8.83877086639404296875e+00) (7, -9.92611885070800781250e+00) (8, -1.32776260375976562500e+01) (9, -9.15300655364990234375e+00) (10, 1.02652273178100585938e+01) (11, 9.18856143951416015625e+00) (12, 9.98003864288330078125e+00) (13, 1.57217073440551757812e+01) (14, 1.19916486740112304688e+01) (4, -1.30601334571838378906e+00) (5, -1.13241605460643768311e-01) (6, -5.36936104297637939453e-01) (7, -1.85695815086364746094e+00) (8, 1.07477366924285888672e+00) (9, -5.36811828613281250000e+00) (10, 2.47740936279296875000e+00) (11, 1.30634784698486328125e+00) (12, -5.80797255039215087891e-01) (13, 7.24099338054656982422e-01) (14, -3.04102635383605957031e+00) (4, -1.58767914772033691406e+00) (5, -5.44171953201293945312e+00) (6, 1.87600767612457275391e+00) (7, 1.41371440887451171875e+00) (8, -3.19617176055908203125e+00) (9, -7.80486631393432617188e+00) (10, -4.62067651748657226562e+00) (11, -1.30762016773223876953e+00) (12, 1.54157531261444091797e+00) (13, 5.43805932998657226562e+00) (14, -1.71997344493865966797e+00) 
