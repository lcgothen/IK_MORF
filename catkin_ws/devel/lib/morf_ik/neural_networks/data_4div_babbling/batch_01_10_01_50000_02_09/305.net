FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.195438 -0.044186 0.058008 
scale_deviation_in=0.013826 0.015321 0.013045 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.792869 1.498111 -2.151315 
scale_deviation_out=0.075873 0.400387 0.579244 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 2.77249813079833984375e+00) (1, -3.44097882509231567383e-01) (2, 1.33525395393371582031e+00) (3, 2.11195683479309082031e+00) (0, 9.38837945461273193359e-01) (1, 2.70052459090948104858e-02) (2, 5.92773914337158203125e-01) (3, -4.58635032176971435547e-01) (0, -2.39290446043014526367e-01) (1, -7.19187259674072265625e-02) (2, -2.94152885675430297852e-01) (3, 1.91302716732025146484e+00) (0, 9.42769497632980346680e-02) (1, -6.12871646881103515625e-02) (2, 5.64662098884582519531e-01) (3, -2.73818016052246093750e+00) (0, -8.26959669589996337891e-01) (1, -3.38214325904846191406e+00) (2, 1.73650216311216354370e-02) (3, -3.86439681053161621094e+00) (0, -3.90391528606414794922e-01) (1, -3.22820925712585449219e+00) (2, -3.19363437592983245850e-02) (3, 3.30567479133605957031e+00) (0, 3.76180028915405273438e+00) (1, -9.95548665523529052734e-01) (2, 8.56913805007934570312e-01) (3, 3.59814167022705078125e+00) (0, 5.45812308788299560547e-01) (1, 3.17979723215103149414e-01) (2, -2.73561775684356689453e-01) (3, -2.15871453285217285156e+00) (0, -2.96858549118041992188e+00) (1, 1.09582698345184326172e+00) (2, -1.17475259304046630859e+00) (3, -2.65024089813232421875e+00) (0, 6.53372943401336669922e-01) (1, -4.06569689512252807617e-01) (2, -5.31091868877410888672e-01) (3, -2.52314186096191406250e+00) (4, 1.93625777959823608398e-01) (5, -5.21846711635589599609e-02) (6, -1.44593441486358642578e+00) (7, -2.07281753420829772949e-01) (8, -5.13321161270141601562e+00) (9, -3.62443137168884277344e+00) (10, 3.22862952947616577148e-01) (11, 2.17953276634216308594e+00) (12, 6.10567033290863037109e-01) (13, -9.58170175552368164062e-01) (14, 2.75956541299819946289e-01) (4, -3.81821751594543457031e+00) (5, -1.37846636772155761719e+00) (6, 1.49757218360900878906e+00) (7, -2.17121171951293945312e+00) (8, -6.10815525054931640625e-01) (9, -1.21057689189910888672e-01) (10, -5.21673727035522460938e+00) (11, -2.59393382072448730469e+00) (12, 3.84507656097412109375e+00) (13, -4.03112649917602539062e+00) (14, 2.89440608024597167969e+00) (4, -3.59657287597656250000e+00) (5, -2.32790660858154296875e+00) (6, 2.66063237190246582031e+00) (7, -3.26249837875366210938e+00) (8, -7.03269183635711669922e-01) (9, -1.04190446436405181885e-01) (10, -4.68582057952880859375e+00) (11, -9.04213070869445800781e-01) (12, 4.47812223434448242188e+00) (13, -2.57768011093139648438e+00) (14, 3.29770803451538085938e+00) 
