FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=-0.022486 -0.019509 -0.075044 
scale_deviation_in=0.003743 0.002463 0.012728 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.852083 -0.013420 -0.304681 
scale_deviation_out=0.092317 0.068639 0.122392 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 3.55313837528228759766e-01) (1, 8.92513334751129150391e-01) (2, -1.17410445213317871094e+00) (3, 7.48225629329681396484e-01) (0, -4.39164265990257263184e-02) (1, -4.67133760452270507812e-01) (2, 1.59048390388488769531e+00) (3, 9.54272389411926269531e-01) (0, 9.07447636127471923828e-01) (1, -8.42756330966949462891e-01) (2, 5.08441686630249023438e-01) (3, 7.04490780830383300781e-01) (0, -1.10894274711608886719e+00) (1, -1.83710366487503051758e-01) (2, -4.41703796386718750000e-01) (3, 5.87188303470611572266e-01) (0, 5.93599438667297363281e-01) (1, 6.46909713745117187500e-01) (2, 6.36335670948028564453e-01) (3, -9.78031814098358154297e-01) (0, 8.86368691921234130859e-01) (1, 1.02997802197933197021e-01) (2, 8.80426764488220214844e-01) (3, 9.19141899794340133667e-03) (0, 5.77283322811126708984e-01) (1, 7.65860021114349365234e-01) (2, 8.91572892665863037109e-01) (3, 8.18229317665100097656e-01) (0, -1.18296301364898681641e+00) (1, 6.11233890056610107422e-01) (2, 1.00132048130035400391e+00) (3, -2.88721144199371337891e-01) (0, 6.08427047729492187500e-01) (1, -1.38938271999359130859e+00) (2, -3.86902362108230590820e-01) (3, -6.58064335584640502930e-02) (0, -1.22458338737487792969e+00) (1, -2.56343901157379150391e-01) (2, -3.10779571533203125000e-01) (3, -1.87235951423645019531e-01) (4, -5.32799303531646728516e-01) (5, -2.41343863308429718018e-02) (6, 1.82195770740509033203e+00) (7, -6.17646634578704833984e-01) (8, 2.05514967441558837891e-01) (9, 1.95521637797355651855e-01) (10, -3.01284670829772949219e-01) (11, -1.52495145797729492188e+00) (12, 1.68932759761810302734e+00) (13, -1.28590798377990722656e+00) (14, -4.37319725751876831055e-01) (4, 1.30750989913940429688e+00) (5, 4.14164036512374877930e-01) (6, -7.90070891380310058594e-02) (7, -9.41550970077514648438e-01) (8, 4.88080918788909912109e-01) (9, 1.55022251605987548828e+00) (10, 2.62120544910430908203e-01) (11, -8.25355350971221923828e-01) (12, -1.00224423408508300781e+00) (13, -1.50820708274841308594e+00) (14, -3.58173519372940063477e-01) (4, -6.56712532043457031250e-01) (5, 1.70896899700164794922e+00) (6, 1.17636106908321380615e-01) (7, -5.23748815059661865234e-01) (8, 7.33767271041870117188e-01) (9, 1.20729565620422363281e+00) (10, 5.97401261329650878906e-01) (11, 1.25345563888549804688e+00) (12, -1.70466750860214233398e-01) (13, -8.83881747722625732422e-01) (14, -1.26161202788352966309e-01) 
