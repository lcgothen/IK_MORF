FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.099542 0.034150 -0.020376 
scale_deviation_in=0.013822 0.017159 0.013349 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.240495 2.788622 0.082668 
scale_deviation_out=0.168191 0.391217 0.216573 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.27931666374206542969e-01) (1, -3.30225729942321777344e+00) (2, -1.26249901950359344482e-02) (3, -3.87184405326843261719e+00) (0, 7.53697335720062255859e-01) (1, -7.20369100570678710938e-01) (2, -7.54241466522216796875e-01) (3, -4.01809722185134887695e-01) (0, -3.63862037658691406250e-01) (1, 1.26251220703125000000e+00) (2, -2.13861316442489624023e-01) (3, -2.36955165863037109375e+00) (0, -8.32874178886413574219e-01) (1, 3.21318358182907104492e-01) (2, 3.72969150543212890625e-01) (3, -2.60265439748764038086e-01) (0, -1.73076167702674865723e-01) (1, -1.37372279167175292969e+00) (2, -2.85226613283157348633e-01) (3, 6.89846038818359375000e-01) (0, -8.04609358310699462891e-01) (1, -2.81080063432455062866e-02) (2, -7.03094899654388427734e-01) (3, 9.53824877738952636719e-01) (0, 6.01606225967407226562e+00) (1, 2.74619936943054199219e+00) (2, -2.74986672401428222656e+00) (3, 7.73196411132812500000e+00) (0, -1.79824471473693847656e+00) (1, -6.56265854835510253906e-01) (2, 1.83701360225677490234e+00) (3, 3.82786226272583007812e+00) (0, -1.01533985137939453125e+00) (1, 1.69264400005340576172e+00) (2, 1.08642399311065673828e-01) (3, -2.48863244056701660156e+00) (0, 3.12549501657485961914e-01) (1, 2.33624309301376342773e-01) (2, 7.96547532081604003906e-01) (3, 1.64645373821258544922e+00) (4, -4.22648715972900390625e+00) (5, 7.79188990592956542969e-01) (6, 2.31919217109680175781e+00) (7, 8.81970822811126708984e-01) (8, -7.42078840732574462891e-01) (9, -8.96370783448219299316e-02) (10, 1.00651502609252929688e-01) (11, 1.14993929862976074219e-01) (12, 2.77353572845458984375e+00) (13, 7.66886621713638305664e-02) (14, 4.89362508058547973633e-01) (4, 2.70262032747268676758e-01) (5, -1.58023750782012939453e+00) (6, -2.75124025344848632812e+00) (7, 1.38812661170959472656e+00) (8, 1.25592350959777832031e+00) (9, 1.29114353656768798828e+00) (10, -1.12320518493652343750e+01) (11, 4.17805147171020507812e+00) (12, 2.76205807924270629883e-01) (13, 2.53357815742492675781e+00) (14, 2.81637907028198242188e+00) (4, 1.65325065609067678452e-03) (5, -1.53394305706024169922e+00) (6, -1.73680758476257324219e+00) (7, 1.57059657573699951172e+00) (8, 2.46794939041137695312e+00) (9, 2.61839199066162109375e+00) (10, -3.75090718269348144531e+00) (11, 2.19420123100280761719e+00) (12, 5.55053651332855224609e-01) (13, -4.69532907009124755859e-01) (14, -7.46888399124145507812e-01) 
