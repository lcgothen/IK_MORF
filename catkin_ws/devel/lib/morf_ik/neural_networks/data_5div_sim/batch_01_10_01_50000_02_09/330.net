FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.133890 0.086412 -0.160199 
scale_deviation_in=0.007263 0.010783 0.004661 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.998312 0.080257 -2.312568 
scale_deviation_out=0.068832 0.127738 0.217834 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 6.72756433486938476562e-01) (1, 1.09658253192901611328e+00) (2, -9.28473651409149169922e-01) (3, -2.08704066276550292969e+00) (0, -8.52490901947021484375e-01) (1, 3.59313301742076873779e-02) (2, 7.69079253077507019043e-02) (3, 1.65607142448425292969e+00) (0, 8.88646900653839111328e-01) (1, 1.68897390365600585938e-01) (2, -2.38414311408996582031e+00) (3, 6.14872515201568603516e-01) (0, 3.24723625183105468750e+00) (1, 8.17999184131622314453e-01) (2, -3.09536314010620117188e+00) (3, 2.33669447898864746094e+00) (0, 1.46820271015167236328e+00) (1, -2.37649846076965332031e+00) (2, -5.90773165225982666016e-01) (3, 4.43718862533569335938e+00) (0, 1.51524341106414794922e+00) (1, 1.72506368160247802734e+00) (2, -3.52250099182128906250e+00) (3, 2.53463125228881835938e+00) (0, -7.65175461769104003906e-01) (1, -1.96649360656738281250e+00) (2, 8.79151463508605957031e-01) (3, -3.40415239334106445312e-01) (0, -4.57092380523681640625e+00) (1, -4.19599866867065429688e+00) (2, 4.91849470138549804688e+00) (3, -4.30797910690307617188e+00) (0, 1.16332113742828369141e+00) (1, -5.28661191463470458984e-01) (2, -8.89634191989898681641e-01) (3, -2.78504657745361328125e+00) (0, -1.55944311618804931641e+00) (1, -1.73139309883117675781e+00) (2, -2.56531929969787597656e+00) (3, 3.15013623237609863281e+00) (4, 1.45933341979980468750e+00) (5, 3.51165723800659179688e+00) (6, -5.03144025802612304688e-01) (7, -1.94071805477142333984e+00) (8, -3.97728586196899414062e+00) (9, 9.97808575630187988281e-01) (10, -1.49835419654846191406e+00) (11, -9.51158165931701660156e-01) (12, -2.13264846801757812500e+00) (13, -2.64380633831024169922e-01) (14, 7.40434765815734863281e-01) (4, -5.91087150573730468750e+00) (5, 1.02240455150604248047e+00) (6, -3.19693231582641601562e+00) (7, -4.16644477844238281250e+00) (8, 3.99619150161743164062e+00) (9, -3.96153163909912109375e+00) (10, 2.15910673141479492188e+00) (11, 7.51793766021728515625e+00) (12, -3.57192492485046386719e+00) (13, 3.42713046073913574219e+00) (14, 2.38583469390869140625e+00) (4, -4.32206153869628906250e+00) (5, 2.24685811996459960938e+00) (6, -1.60516333580017089844e+00) (7, -3.81050753593444824219e+00) (8, 3.33028388023376464844e+00) (9, -3.83460330963134765625e+00) (10, 2.97791910171508789062e+00) (11, 7.07081794738769531250e+00) (12, -4.16425085067749023438e+00) (13, 3.44420266151428222656e+00) (14, 1.57821393013000488281e+00) 
