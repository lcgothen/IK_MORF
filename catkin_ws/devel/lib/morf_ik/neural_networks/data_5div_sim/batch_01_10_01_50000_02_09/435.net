FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.197515 0.094869 0.008732 
scale_deviation_in=0.010192 0.014365 0.010295 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.122909 1.117512 -2.282743 
scale_deviation_out=0.070163 0.332601 0.508623 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -1.42922878265380859375e-01) (1, 2.11852028965950012207e-01) (2, 5.13239681720733642578e-01) (3, 1.37645137310028076172e+00) (0, -2.00441665947437286377e-03) (1, -9.14439409971237182617e-02) (2, 3.78245413303375244141e-02) (3, -2.38888192176818847656e+00) (0, -8.38906019926071166992e-02) (1, 2.24151834845542907715e-01) (2, -2.23061203956604003906e-01) (3, -2.61943292617797851562e+00) (0, 3.02756279706954956055e-01) (1, -7.20509171485900878906e-01) (2, -2.28752776980400085449e-01) (3, -1.35359084606170654297e+00) (0, 1.37533932924270629883e-01) (1, -7.15726315975189208984e-01) (2, 3.92728686332702636719e-01) (3, -7.77686595916748046875e-01) (0, 4.88249689340591430664e-01) (1, -9.02618110179901123047e-01) (2, -1.71666279435157775879e-01) (3, 1.99141764640808105469e+00) (0, -1.08743570744991302490e-01) (1, 1.27103161066770553589e-02) (2, 4.42066848278045654297e-01) (3, -2.13088893890380859375e+00) (0, 4.11924310028553009033e-02) (1, -3.53860408067703247070e-01) (2, 6.98743939399719238281e-01) (3, 2.21831059455871582031e+00) (0, -5.08811092376708984375e+00) (1, -3.52839040756225585938e+00) (2, -8.83575856685638427734e-01) (3, -3.10325288772583007812e+00) (0, -4.96843671798706054688e+00) (1, -3.36193966865539550781e+00) (2, -8.77166807651519775391e-01) (3, -3.05832576751708984375e+00) (4, 1.68485724925994873047e+00) (5, -2.16743087768554687500e+00) (6, 1.74488615989685058594e+00) (7, -2.70181441307067871094e+00) (8, -2.61471509933471679688e+00) (9, -3.38857269287109375000e+00) (10, 5.56573629379272460938e-01) (11, -1.29805982112884521484e+00) (12, -6.38092994689941406250e-01) (13, 5.79645633697509765625e-01) (14, 1.67257443070411682129e-01) (4, 1.45095932483673095703e+00) (5, -2.13389968872070312500e+00) (6, -1.89220964908599853516e+00) (7, -9.11496043205261230469e-01) (8, -1.44959539175033569336e-01) (9, 7.89199531078338623047e-01) (10, -1.97898840904235839844e+00) (11, 2.88458275794982910156e+00) (12, 7.36501550674438476562e+00) (13, 6.45044326782226562500e+00) (14, 3.37633061408996582031e+00) (4, 6.99069976806640625000e-01) (5, -2.43407320976257324219e+00) (6, -3.17072176933288574219e+00) (7, -4.26159441471099853516e-01) (8, -8.78698229789733886719e-01) (9, 1.17155158519744873047e+00) (10, -1.90369844436645507812e+00) (11, 1.23746919631958007812e+00) (12, 7.45756006240844726562e+00) (13, 6.67585802078247070312e+00) (14, 3.85614514350891113281e+00) 
