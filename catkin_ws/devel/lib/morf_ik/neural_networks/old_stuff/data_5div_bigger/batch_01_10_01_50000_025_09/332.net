FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.085416 0.152790 0.101994 
scale_deviation_in=0.009889 0.005694 0.005735 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-0.509154 1.796025 -2.059656 
scale_deviation_out=0.055783 0.130185 0.193793 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.43143463134765625000e-01) (1, 2.27115854620933532715e-01) (2, -3.93245220184326171875e-01) (3, -5.21186053752899169922e-01) (0, -1.66685736179351806641e+00) (1, -1.65671551227569580078e+00) (2, -1.43813657760620117188e+00) (3, 1.41643330454826354980e-01) (0, 1.06765377521514892578e+00) (1, 1.54865860939025878906e-01) (2, 3.50479364395141601562e-01) (3, 4.12550210952758789062e-01) (0, 7.91258275508880615234e-01) (1, 3.00056815147399902344e-01) (2, -5.23183584213256835938e-01) (3, 6.13428235054016113281e-01) (0, -1.54321461915969848633e-01) (1, 7.34625637531280517578e-01) (2, 7.09833323955535888672e-01) (3, 9.81840118765830993652e-02) (0, 7.41115570068359375000e-01) (1, 8.19130897521972656250e-01) (2, -7.14833855628967285156e-01) (3, 7.23587930202484130859e-01) (0, 9.68294382095336914062e-01) (1, -7.51918256282806396484e-02) (2, 1.07309198379516601562e+00) (3, -2.72622585296630859375e-01) (0, 1.15299654006958007812e+00) (1, -2.26916968822479248047e-01) (2, -1.81000530719757080078e-01) (3, -3.89145672321319580078e-01) (0, -6.53269410133361816406e-01) (1, 8.33234012126922607422e-01) (2, 2.01103180646896362305e-01) (3, -4.91163045167922973633e-01) (0, 9.23271596431732177734e-01) (1, 1.03930640220642089844e+00) (2, 6.88288509845733642578e-01) (3, -4.29851174354553222656e-01) (4, 2.68517404794692993164e-01) (5, -4.22406047582626342773e-02) (6, -1.11313319206237792969e+00) (7, -6.54018402099609375000e-01) (8, 9.73903656005859375000e-01) (9, -4.28109675645828247070e-01) (10, -1.42544770240783691406e+00) (11, -1.25079965591430664062e+00) (12, 1.02624309062957763672e+00) (13, 4.21949893236160278320e-01) (14, 4.05232131481170654297e-01) (4, 3.54046374559402465820e-01) (5, 2.21135187149047851562e+00) (6, 3.77973681315779685974e-03) (7, -5.28791904449462890625e-01) (8, -8.97625267505645751953e-01) (9, -8.86543393135070800781e-01) (10, -9.55382227897644042969e-01) (11, -3.94553840160369873047e-01) (12, -6.94880008697509765625e-01) (13, -5.65810859203338623047e-01) (14, 1.90363362431526184082e-01) (4, -1.18014283478260040283e-01) (5, 2.22698283195495605469e+00) (6, -9.25286591053009033203e-01) (7, 3.88005197048187255859e-01) (8, -5.79037308692932128906e-01) (9, 5.29716253280639648438e-01) (10, -2.83415019512176513672e-01) (11, -4.46194373071193695068e-02) (12, -1.79042816162109375000e-01) (13, -1.78251743316650390625e+00) (14, -3.72312784194946289062e-01) 
