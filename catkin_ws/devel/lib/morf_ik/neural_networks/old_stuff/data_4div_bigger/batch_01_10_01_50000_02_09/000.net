FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.193370 0.002541 -0.014437 
scale_deviation_in=0.018373 0.021684 0.016634 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.552450 1.573947 -1.336320 
scale_deviation_out=0.116420 0.324986 0.431357 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -3.56973314285278320312e+00) (1, -1.60929906368255615234e+00) (2, -3.70642721652984619141e-01) (3, 3.41433095932006835938e+00) (0, 5.43839693069458007812e-01) (1, 2.79407501220703125000e-02) (2, -1.08087792992591857910e-01) (3, 2.66977119445800781250e+00) (0, 9.27233576774597167969e-01) (1, -1.23563969135284423828e+00) (2, 2.07797780632972717285e-01) (3, 1.30058550834655761719e+00) (0, 2.56802105903625488281e+00) (1, -1.79646253585815429688e+00) (2, 2.35078498721122741699e-01) (3, -2.07687401771545410156e+00) (0, 5.48193931579589843750e-01) (1, -1.88099241256713867188e+00) (2, 5.98068892955780029297e-01) (3, 1.76408874988555908203e+00) (0, -1.28278684616088867188e+00) (1, -1.29890882968902587891e+00) (2, -6.42267942428588867188e-01) (3, -1.05163395404815673828e+00) (0, 9.78533935546875000000e+00) (1, -1.04166306555271148682e-02) (2, -1.95256784558296203613e-01) (3, -1.44860639572143554688e+01) (0, 4.17203330993652343750e+00) (1, 7.62726515531539916992e-02) (2, -3.27268838882446289062e+00) (3, 4.18673068284988403320e-01) (0, 1.46706557273864746094e+00) (1, 9.95526164770126342773e-02) (2, -2.09264063835144042969e+00) (3, -1.34843261912465095520e-02) (0, 4.03627157211303710938e+00) (1, -5.18898189067840576172e-01) (2, -6.07840903103351593018e-02) (3, -9.07288253307342529297e-01) (4, 3.42916220426559448242e-01) (5, 2.11110782623291015625e+00) (6, -3.05251741409301757812e+00) (7, -1.75562036037445068359e+00) (8, -1.06552302837371826172e+00) (9, -1.44208729267120361328e+00) (10, 3.61568999290466308594e+00) (11, 5.44202983379364013672e-01) (12, -8.30607771873474121094e-01) (13, 1.28284227848052978516e+00) (14, 2.23874688148498535156e+00) (4, 4.32584571838378906250e+00) (5, 3.25333046913146972656e+00) (6, 3.47878068685531616211e-01) (7, -4.48405456542968750000e+00) (8, -3.15297317504882812500e+00) (9, 3.82745265960693359375e+00) (10, 1.03422508239746093750e+01) (11, 2.46983337402343750000e+00) (12, -6.38840389251708984375e+00) (13, 3.52023696899414062500e+00) (14, 5.06509160995483398438e+00) (4, 3.58342838287353515625e+00) (5, 2.00993990898132324219e+00) (6, -6.05497717857360839844e-01) (7, -3.66829085350036621094e+00) (8, -2.22308111190795898438e+00) (9, 3.74951744079589843750e+00) (10, 8.21792316436767578125e+00) (11, 2.26429200172424316406e+00) (12, -4.77124023437500000000e+00) (13, 2.44331049919128417969e+00) (14, 4.84668207168579101562e+00) 
