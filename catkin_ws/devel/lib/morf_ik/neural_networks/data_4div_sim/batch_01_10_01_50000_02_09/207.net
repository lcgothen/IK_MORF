FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.129252 -0.031322 0.143813 
scale_deviation_in=0.016148 0.009412 0.009776 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.808993 1.834055 -2.572228 
scale_deviation_out=0.067214 0.226830 0.338647 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -8.12609791755676269531e-01) (1, -2.35815191268920898438e+00) (2, 8.04356634616851806641e-02) (3, -2.86952733993530273438e+00) (0, -3.42276549339294433594e+00) (1, 5.12522518634796142578e-01) (2, -7.96949565410614013672e-01) (3, -1.82157933712005615234e+00) (0, 9.10625994205474853516e-01) (1, 8.43982696533203125000e-01) (2, 8.56916084885597229004e-02) (3, 1.79183971881866455078e+00) (0, 1.14001363515853881836e-01) (1, -1.14703774452209472656e+00) (2, 6.58559799194335937500e-01) (3, 1.76389133930206298828e+00) (0, -3.36903482675552368164e-02) (1, -1.70882606506347656250e+00) (2, 1.42796099185943603516e-01) (3, 1.93252658843994140625e+00) (0, 2.36340475082397460938e+00) (1, -3.32352757453918457031e-01) (2, 4.40600824356079101562e+00) (3, 1.52963554859161376953e+00) (0, -1.36227619647979736328e+00) (1, -6.08660699799656867981e-03) (2, -6.00303828716278076172e-01) (3, 5.74052512645721435547e-01) (0, 5.12312948703765869141e-01) (1, -9.29895192384719848633e-02) (2, -5.81204891204833984375e-02) (3, 2.35511913895606994629e-01) (0, 4.47039794921875000000e+00) (1, -6.40209853649139404297e-01) (2, 5.86220121383666992188e+00) (3, 6.79356634616851806641e-01) (0, -4.71737575531005859375e+00) (1, 6.99218094348907470703e-01) (2, -2.98071622848510742188e+00) (3, -9.58358049392700195312e-01) (4, -2.66834807395935058594e+00) (5, -1.15257076919078826904e-01) (6, 1.82215774059295654297e+00) (7, -1.64405977725982666016e+00) (8, -3.08567929267883300781e+00) (9, 2.77252376079559326172e-01) (10, -1.50781404972076416016e+00) (11, -1.83395594358444213867e-01) (12, -3.84012609720230102539e-02) (13, 2.93071866035461425781e-01) (14, 8.51088985800743103027e-02) (4, -3.62347722053527832031e-01) (5, -4.10513544082641601562e+00) (6, -4.93173450231552124023e-01) (7, -8.22474807500839233398e-02) (8, -1.90505728125572204590e-01) (9, -3.75432395935058593750e+00) (10, 1.55329942703247070312e+00) (11, -1.04185247421264648438e+00) (12, 4.46201658248901367188e+00) (13, 4.83947753906250000000e+00) (14, 7.29776695370674133301e-02) (4, 1.76500335335731506348e-01) (5, -3.59172010421752929688e+00) (6, 5.80601453781127929688e-01) (7, -9.24865663051605224609e-01) (8, 5.44623553752899169922e-01) (9, -3.47179841995239257812e+00) (10, 1.20778191089630126953e+00) (11, 9.50848758220672607422e-01) (12, 3.92869234085083007812e+00) (13, 4.23825883865356445312e+00) (14, -2.22035065293312072754e-01) 
