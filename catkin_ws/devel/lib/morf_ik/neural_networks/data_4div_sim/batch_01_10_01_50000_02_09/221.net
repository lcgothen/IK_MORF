FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.131638 0.078174 -0.123709 
scale_deviation_in=0.019744 0.018247 0.013260 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.034583 0.786765 -1.422383 
scale_deviation_out=0.116980 0.283039 0.450214 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.03475622832775115967e-01) (1, -2.16780495643615722656e+00) (2, 4.36743855476379394531e-01) (3, 1.32508075237274169922e+00) (0, -2.42444396018981933594e-01) (1, 7.30321332812309265137e-02) (2, 5.13390064239501953125e-01) (3, -2.32459855079650878906e+00) (0, 7.02246844768524169922e-01) (1, 9.30651009082794189453e-01) (2, -1.02255690097808837891e+00) (3, 3.81410288810729980469e+00) (0, -2.00217795372009277344e+00) (1, -7.51637816429138183594e-02) (2, -4.15154248476028442383e-01) (3, 9.27743732929229736328e-01) (0, 5.92307567596435546875e-01) (1, 1.48198294639587402344e+00) (2, -3.07470202445983886719e-01) (3, 2.23313763737678527832e-01) (0, 8.47336292266845703125e-01) (1, -4.03447449207305908203e-01) (2, 1.33443427085876464844e+00) (3, -1.10956020653247833252e-01) (0, -4.12805639207363128662e-02) (1, -7.65848606824874877930e-02) (2, 3.86759132146835327148e-01) (3, -2.08841896057128906250e+00) (0, 1.38596430420875549316e-01) (1, 7.48051822185516357422e-01) (2, 9.40608441829681396484e-01) (3, 1.46904215216636657715e-01) (0, 1.70898318290710449219e+00) (1, -4.99128073453903198242e-01) (2, -6.07379153370857238770e-02) (3, 2.10192465782165527344e+00) (0, 5.51123189926147460938e+00) (1, 3.47300004959106445312e+00) (2, -4.59394979476928710938e+00) (3, -9.99395370483398437500e+00) (4, 3.53762768208980560303e-02) (5, 1.37906885147094726562e+00) (6, 2.67961764335632324219e+00) (7, 1.85801208019256591797e+00) (8, 2.60682368278503417969e+00) (9, -3.67886722087860107422e-01) (10, 1.22390799224376678467e-01) (11, 1.98833572864532470703e+00) (12, -3.35803389549255371094e+00) (13, 2.03047662973403930664e-01) (14, 3.40248823165893554688e-01) (4, 6.09164595603942871094e-01) (5, 2.18964314460754394531e+00) (6, -3.12353539466857910156e+00) (7, 1.65573608875274658203e+00) (8, 1.02887526154518127441e-01) (9, 1.92139828205108642578e+00) (10, 2.03797030448913574219e+00) (11, 8.82326245307922363281e-01) (12, -6.81795716285705566406e-01) (13, -1.02593135833740234375e+01) (14, -3.84307146072387695312e+00) (4, 1.04554092884063720703e+00) (5, 3.49141335487365722656e+00) (6, -4.28254556655883789062e+00) (7, 1.85459613800048828125e+00) (8, 6.55740499496459960938e-01) (9, 1.47592723369598388672e+00) (10, 2.54214334487915039062e+00) (11, -6.41602814197540283203e-01) (12, -1.19415438175201416016e+00) (13, -1.45670471191406250000e+01) (14, -5.51751995086669921875e+00) 
