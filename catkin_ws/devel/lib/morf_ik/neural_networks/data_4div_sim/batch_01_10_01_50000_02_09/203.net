FANN_FLO_2.1
num_layers=3
learning_rate=0.100000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=1
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=4 11 4 
scale_included=1
scale_mean_in=0.141167 -0.034525 -0.037024 
scale_deviation_in=0.015114 0.010974 0.012348 
scale_new_min_in=-0.900000 -0.900000 -0.900000 
scale_factor_in=0.900000 0.900000 0.900000 
scale_mean_out=-1.810311 2.005514 -0.557003 
scale_deviation_out=0.071003 0.149188 0.204353 
scale_new_min_out=-0.900000 -0.900000 -0.900000 
scale_factor_out=0.900000 0.900000 0.900000 
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (4, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (11, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 4.00573909282684326172e-01) (1, 7.20355927944183349609e-01) (2, 9.99863147735595703125e-01) (3, -2.35510855913162231445e-01) (0, -1.01280093193054199219e+00) (1, 6.94036409258842468262e-02) (2, 1.15416204929351806641e+00) (3, 6.88226401805877685547e-01) (0, 1.57029896974563598633e-01) (1, -1.28543770313262939453e+00) (2, -6.83953240513801574707e-02) (3, -3.02093416452407836914e-01) (0, -1.50701749324798583984e+00) (1, -1.66083186864852905273e-01) (2, -2.20961019396781921387e-01) (3, -4.21565085649490356445e-01) (0, -4.25767712295055389404e-02) (1, 1.49001944065093994141e+00) (2, -8.07111024856567382812e-01) (3, -4.41137373447418212891e-01) (0, -9.17054176330566406250e-01) (1, -1.18715214729309082031e+00) (2, 8.44989418983459472656e-02) (3, 3.25810670852661132812e-01) (0, 8.30568194389343261719e-01) (1, -2.85084843635559082031e-01) (2, -2.71296948194503784180e-01) (3, 4.58931863307952880859e-01) (0, -8.58054697513580322266e-01) (1, 3.97532522678375244141e-01) (2, 1.33664572238922119141e+00) (3, -2.81683802604675292969e-01) (0, -1.37234938144683837891e+00) (1, 7.32710957527160644531e-01) (2, 8.15517246723175048828e-01) (3, 6.04274570941925048828e-01) (0, -1.38046890497207641602e-01) (1, 9.22999441623687744141e-01) (2, 5.41733562946319580078e-01) (3, 9.10434961318969726562e-01) (4, 1.15989100933074951172e+00) (5, -1.03441409766674041748e-01) (6, -1.46956145763397216797e+00) (7, -6.69552147388458251953e-01) (8, 1.56865298748016357422e+00) (9, -1.34156024456024169922e+00) (10, -1.18043817579746246338e-01) (11, -3.91247004270553588867e-01) (12, -9.57662798464298248291e-03) (13, 8.24325501918792724609e-01) (14, -7.32061341404914855957e-02) (4, 8.84821355342864990234e-01) (5, 1.11102139949798583984e+00) (6, -3.20317685604095458984e-01) (7, 9.86657977104187011719e-01) (8, -4.44893479347229003906e-01) (9, 7.56036698818206787109e-01) (10, -1.14134156703948974609e+00) (11, 1.53284645080566406250e+00) (12, 1.22540926933288574219e+00) (13, -1.75769090652465820312e-01) (14, -1.51477470993995666504e-01) (4, -1.20641434192657470703e+00) (5, 7.74214029312133789062e-01) (6, -4.13099974393844604492e-01) (7, 1.50916254520416259766e+00) (8, 7.35837936401367187500e-01) (9, 8.34076523780822753906e-01) (10, -2.89179682731628417969e-01) (11, 3.79977434873580932617e-01) (12, 1.46331202983856201172e+00) (13, 5.99712789058685302734e-01) (14, -5.61631858348846435547e-01) 
